{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Notebook\n",
    "\n",
    "This notebook mainly discusses a Low-Rank Tensor Completion (LRTC) model which is called High accuracy LRTC (HaLRTC) in the following article:\n",
    "\n",
    "> Ji Liu, Przemyslaw Musialski, Peter Wonka, Jieping Ye, 2013. **Tensor completion for estimating missing values in visual data**. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(1): 208-220.\n",
    "\n",
    "\n",
    "## Quick Run\n",
    "\n",
    "This notebook is publicly available for any usage at our data imputation project. Please click [**transdim - GitHub**](https://github.com/xinychen/transdim).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Tensor Unfolding (`ten2mat`) and Matrix Folding (`mat2ten`)\n",
    "\n",
    "Using numpy reshape to perform 3rd rank tensor unfold operation. [[**link**](https://stackoverflow.com/questions/49970141/using-numpy-reshape-to-perform-3rd-rank-tensor-unfold-operation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:\n",
      "(3, 2, 4)\n",
      "original tensor:\n",
      "[[[ 1  2  3  4]\n",
      "  [ 3  4  5  6]]\n",
      "\n",
      " [[ 5  6  7  8]\n",
      "  [ 7  8  9 10]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [11 12 13 14]]]\n",
      "\n",
      "(1) mode-1 tensor unfolding:\n",
      "[[ 1  3  2  4  3  5  4  6]\n",
      " [ 5  7  6  8  7  9  8 10]\n",
      " [ 9 11 10 12 11 13 12 14]]\n",
      "\n",
      "(2) mode-2 tensor unfolding:\n",
      "[[ 1  5  9  2  6 10  3  7 11  4  8 12]\n",
      " [ 3  7 11  4  8 12  5  9 13  6 10 14]]\n",
      "\n",
      "(3) mode-3 tensor unfolding:\n",
      "[[ 1  5  9  3  7 11]\n",
      " [ 2  6 10  4  8 12]\n",
      " [ 3  7 11  5  9 13]\n",
      " [ 4  8 12  6 10 14]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[[1, 2, 3, 4], [3, 4, 5, 6]], \n",
    "              [[5, 6, 7, 8], [7, 8, 9, 10]], \n",
    "              [[9, 10, 11, 12], [11, 12, 13, 14]]])\n",
    "print('tensor size:')\n",
    "print(X.shape)\n",
    "print('original tensor:')\n",
    "print(X)\n",
    "print()\n",
    "print('(1) mode-1 tensor unfolding:')\n",
    "print(ten2mat(X, 0))\n",
    "print()\n",
    "print('(2) mode-2 tensor unfolding:')\n",
    "print(ten2mat(X, 1))\n",
    "print()\n",
    "print('(3) mode-3 tensor unfolding:')\n",
    "print(ten2mat(X, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat2ten(mat, tensor_size, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(tensor_size.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(tensor_size[index]), order = 'F'), 0, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: High accuracy Low-Rank Tensor Completion (HaLRTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svt(mat, lambda0): ## Singular value thresholding (SVT)\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "    vec = s - lambda0\n",
    "    vec[np.where(vec < 0)] = 0\n",
    "    \n",
    "    return np.matmul(np.matmul(u, np.diag(vec)), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter):\n",
    "    \"\"\"High accuracy Low-Rank Tensor Completion, HaLRTC.\"\"\"\n",
    "    \n",
    "    dim0 = sparse_tensor.ndim\n",
    "    dim1, dim2, dim3 = sparse_tensor.shape\n",
    "    pos = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    position = np.where(sparse_tensor != 0)\n",
    "    binary_tensor = np.zeros((dim1, dim2, dim3))\n",
    "    binary_tensor[position] = 1\n",
    "    tensor_hat = sparse_tensor.copy()\n",
    "    \n",
    "    Z = np.zeros((dim1, dim2, dim3, dim0)) # \\boldsymbol{\\mathcal{Z}} (n1*n2*3*d)\n",
    "    T = np.zeros((dim1, dim2, dim3, dim0)) # \\boldsymbol{\\mathcal{T}} (n1*n2*3*d)\n",
    "    \n",
    "    for iters in range(maxiter):\n",
    "        for k in range(dim0):\n",
    "            Z[:, :, :, k] = mat2ten(svt(ten2mat(tensor_hat + T[:, :, :, k] / rho, k), \n",
    "                                        alpha[k] / rho), np.array([dim1, dim2, dim3]), k)\n",
    "        tensor_hat = np.mean(Z - T / rho, axis = 3)\n",
    "        tensor_hat[position] = sparse_tensor[position]\n",
    "        for k in range(dim0):\n",
    "            T[:, :, :, k] = T[:, :, :, k] + rho * (tensor_hat - Z[:, :, :, k])\n",
    "\n",
    "        rmse = np.sqrt(np.sum((dense_tensor[pos] - tensor_hat[pos]) ** 2) / dense_tensor[pos].shape[0])\n",
    "        if (iters + 1) % 200 == 0:\n",
    "            print('Iter: {}'.format(iters + 1))\n",
    "            print('RMSE: {:.6}'.format(rmse))\n",
    "            print()\n",
    "\n",
    "    if maxiter >= 100:\n",
    "        final_mape = np.sum(np.abs(dense_tensor[pos] - tensor_hat[pos]) / dense_tensor[pos]) / dense_tensor[pos].shape[0]\n",
    "        final_rmse = np.sqrt(np.sum((dense_tensor[pos] - tensor_hat[pos]) ** 2) / dense_tensor[pos].shape[0])\n",
    "        print('Imputation MAPE: {:.6}'.format(final_mape))\n",
    "        print('Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "        print()\n",
    "\n",
    "    return tensor_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Data Organization\n",
    "\n",
    "## 1) Matrix Structure\n",
    "\n",
    "We consider a dataset of $m$ discrete time series $\\boldsymbol{y}_{i}\\in\\mathbb{R}^{f},i\\in\\left\\{1,2,...,m\\right\\}$. The time series may have missing elements. We express spatio-temporal dataset as a matrix $Y\\in\\mathbb{R}^{m\\times f}$ with $m$ rows (e.g., locations) and $f$ columns (e.g., discrete time intervals),\n",
    "\n",
    "$$Y=\\left[ \\begin{array}{cccc} y_{11} & y_{12} & \\cdots & y_{1f} \\\\ y_{21} & y_{22} & \\cdots & y_{2f} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_{m1} & y_{m2} & \\cdots & y_{mf} \\\\ \\end{array} \\right]\\in\\mathbb{R}^{m\\times f}.$$\n",
    "\n",
    "## 2) Tensor Structure\n",
    "\n",
    "We consider a dataset of $m$ discrete time series $\\boldsymbol{y}_{i}\\in\\mathbb{R}^{nf},i\\in\\left\\{1,2,...,m\\right\\}$. The time series may have missing elements. We partition each time series into intervals of predifined length $f$. We express each partitioned time series as a matrix $Y_{i}$ with $n$ rows (e.g., days) and $f$ columns (e.g., discrete time intervals per day),\n",
    "\n",
    "$$Y_{i}=\\left[ \\begin{array}{cccc} y_{11} & y_{12} & \\cdots & y_{1f} \\\\ y_{21} & y_{22} & \\cdots & y_{2f} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_{n1} & y_{n2} & \\cdots & y_{nf} \\\\ \\end{array} \\right]\\in\\mathbb{R}^{n\\times f},i=1,2,...,m,$$\n",
    "\n",
    "therefore, the resulting structure is a tensor $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Experiments on Guangzhou Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 3.3328\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 3.33242\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 3.33247\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 3.33245\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 3.33245\n",
      "\n",
      "Imputation MAPE: 0.0815113\n",
      "Imputation RMSE: 3.33245\n",
      "\n",
      "Running time: 961 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.01\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 3.65684\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 3.61437\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 3.61432\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 3.61427\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 3.61426\n",
      "\n",
      "Imputation MAPE: 0.0887212\n",
      "Imputation RMSE: 3.61426\n",
      "\n",
      "Running time: 982 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.01\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 6.3564\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 4.2148\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 4.20912\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 4.20865\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 4.20858\n",
      "\n",
      "Imputation MAPE: 0.104594\n",
      "Imputation RMSE: 4.20858\n",
      "\n",
      "Running time: 938 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.01\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 17.2941\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 5.09387\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 4.42171\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 4.38976\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 4.38132\n",
      "\n",
      "Imputation MAPE: 0.108805\n",
      "Imputation RMSE: 4.38132\n",
      "\n",
      "Running time: 958 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.01\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of missing data imputation using HaLRTC:\n",
    "\n",
    "|  scenario |`alpha` (vector input)|`rho`|`maxiter`|       mape |      rmse |\n",
    "|:----------|-----:|---------:|---------:|-------- --:|----------:|\n",
    "|**0.2, RM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.01 | 1000 | **0.0815** | **3.33**|\n",
    "|**0.4, RM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.01 | 1000 | **0.0887** | **3.61**|\n",
    "|**0.2, NM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.01 | 1000 | **0.1046** | **4.21**|\n",
    "|**0.4, NM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.01 | 1000 | **0.1088** | **4.38**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Experiments on Birmingham Data Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.1\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 17.4024\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 17.3576\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 17.3514\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 17.351\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 17.3511\n",
      "\n",
      "Imputation MAPE: 0.0485009\n",
      "Imputation RMSE: 17.3511\n",
      "\n",
      "Running time: 11 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.001\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 27.1823\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 26.8319\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 26.7962\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 26.7923\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 26.7919\n",
      "\n",
      "Imputation MAPE: 0.0664143\n",
      "Imputation RMSE: 26.7919\n",
      "\n",
      "Running time: 11 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.001\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.1\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 62.3232\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 35.3005\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 34.7651\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 34.7215\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 34.7161\n",
      "\n",
      "Imputation MAPE: 0.0946557\n",
      "Imputation RMSE: 34.7161\n",
      "\n",
      "Running time: 11 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.001\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 341.995\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 158.246\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 105.057\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 94.7617\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 92.5922\n",
      "\n",
      "Imputation MAPE: 0.14828\n",
      "Imputation RMSE: 92.5922\n",
      "\n",
      "Running time: 11 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.001\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of missing data imputation using HaLRTC:\n",
    "\n",
    "|  scenario |`alpha` (vector input)|`rho`|`maxiter`|       mape |      rmse |\n",
    "|:----------|-----:|---------:|---------:|-------- --:|----------:|\n",
    "|**0.1, RM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.001 | 1000 | **0.0485** | **17.35**|\n",
    "|**0.3, RM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.001 | 1000 | **0.0664** | **26.79**|\n",
    "|**0.1, NM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.001 | 1000 | **0.0947** | **34.72**|\n",
    "|**0.3, NM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.001 | 1000 | **0.1483** | **92.59**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Experiments on Hangzhou Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 28.978\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 28.8789\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 28.8787\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 28.8787\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 28.8787\n",
      "\n",
      "Imputation MAPE: 0.182614\n",
      "Imputation RMSE: 28.8787\n",
      "\n",
      "Running time: 69 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.001\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 32.221\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 31.818\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 31.8141\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 31.8141\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 31.8141\n",
      "\n",
      "Imputation MAPE: 0.1901\n",
      "Imputation RMSE: 31.8141\n",
      "\n",
      "Running time: 63 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.001\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 58.1452\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 43.093\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 40.8895\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 40.5774\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 40.5329\n",
      "\n",
      "Imputation MAPE: 0.202926\n",
      "Imputation RMSE: 40.5329\n",
      "\n",
      "Running time: 61 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.001\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 75.0597\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 58.435\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 54.4693\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 53.5021\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 53.2638\n",
      "\n",
      "Imputation MAPE: 0.214657\n",
      "Imputation RMSE: 53.2638\n",
      "\n",
      "Running time: 62 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.001\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of missing data imputation using HaLRTC:\n",
    "\n",
    "|  scenario |`alpha` (vector input)|`rho`|`maxiter`|       mape |      rmse |\n",
    "|:----------|-----:|---------:|---------:|-------- --:|----------:|\n",
    "|**0.2, RM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.001 | 1000 | **0.1826** | **28.88**|\n",
    "|**0.4, RM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.001 | 1000 | **0.1901** | **31.81**|\n",
    "|**0.2, NM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.001 | 1000 | **0.2029** | **40.53**|\n",
    "|**0.4, NM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.001 | 1000 | **0.2147** | **53.26**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Experiments on Seattle Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "RM_tensor = RM_mat.reshape([RM_mat.shape[0], 28, 288])\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(RM_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 3.49451\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 3.4773\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 3.4773\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 3.4773\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 3.4773\n",
      "\n",
      "Imputation MAPE: 0.0594576\n",
      "Imputation RMSE: 3.4773\n",
      "\n",
      "Running time: 1233 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.01\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "RM_tensor = RM_mat.reshape([RM_mat.shape[0], 28, 288])\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(RM_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 5.95185\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 3.84158\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 3.8411\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 3.8411\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 3.8411\n",
      "\n",
      "Imputation MAPE: 0.0677406\n",
      "Imputation RMSE: 3.8411\n",
      "\n",
      "Running time: 1304 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.01\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "NM_mat = pd.read_csv('../datasets/Seattle-data-set/NM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "NM_mat = NM_mat.values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 28, 288))\n",
    "for i1 in range(binary_tensor.shape[0]):\n",
    "    for i2 in range(binary_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(NM_mat[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 34.6249\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 14.4031\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 5.06751\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 4.70646\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 4.70185\n",
      "\n",
      "Imputation MAPE: 0.0882067\n",
      "Imputation RMSE: 4.70185\n",
      "\n",
      "Running time: 1282 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.01\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "NM_mat = pd.read_csv('../datasets/Seattle-data-set/NM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "NM_mat = NM_mat.values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 28, 288))\n",
    "for i1 in range(binary_tensor.shape[0]):\n",
    "    for i2 in range(binary_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(NM_mat[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "RMSE: 5.27941\n",
      "\n",
      "Iter: 400\n",
      "RMSE: 5.2794\n",
      "\n",
      "Iter: 600\n",
      "RMSE: 5.2794\n",
      "\n",
      "Iter: 800\n",
      "RMSE: 5.2794\n",
      "\n",
      "Iter: 1000\n",
      "RMSE: 5.2794\n",
      "\n",
      "Imputation MAPE: 0.102027\n",
      "Imputation RMSE: 5.2794\n",
      "\n",
      "Running time: 1234 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 0.001\n",
    "maxiter = 1000\n",
    "HaLRTC(dense_tensor, sparse_tensor, alpha, rho, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of missing data imputation using HaLRTC:\n",
    "\n",
    "|  scenario |`alpha` (vector input)|`rho`|`maxiter`|       mape |      rmse |\n",
    "|:----------|-----:|---------:|---------:|-------- --:|----------:|\n",
    "|**0.2, RM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.01 | 1000 | **0.0595** | **3.48**|\n",
    "|**0.4, RM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.01 | 1000 | **0.0677** | **3.84**|\n",
    "|**0.2, NM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.01 | 1000 | **0.0882** | **4.70**|\n",
    "|**0.4, NM**| $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$ | 0.001 | 1000 | **0.1020** | **5.28**|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
