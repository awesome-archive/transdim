{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Quick Run\n",
    "\n",
    "This notebook is publicly available for any usage at our data imputation project. Please click [**transdim**](https://github.com/xinychen/transdim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary dependencies. We will make use of `numpy` and `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Matrix Computation Concepts\n",
    "\n",
    "## 1) Kronecker product\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "Given two matrices $A\\in\\mathbb{R}^{m_1\\times n_1}$ and $B\\in\\mathbb{R}^{m_2\\times n_2}$, then, the **Kronecker product** between these two matrices is defined as\n",
    "\n",
    "$$A\\otimes B=\\left[ \\begin{array}{cccc} a_{11}B & a_{12}B & \\cdots & a_{1m_2}B \\\\ a_{21}B & a_{22}B & \\cdots & a_{2m_2}B \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m_11}B & a_{m_12}B & \\cdots & a_{m_1m_2}B \\\\ \\end{array} \\right]$$\n",
    "where the symbol $\\otimes$ denotes Kronecker product, and the size of resulted $A\\otimes B$ is $(m_1m_2)\\times (n_1n_2)$ (i.e., $m_1\\times m_2$ columns and $n_1\\times n_2$ rows).\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "If $A=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]$ and $B=\\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10 \\\\ \\end{array} \\right]$, then, we have\n",
    "\n",
    "$$A\\otimes B=\\left[ \\begin{array}{cc} 1\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] & 2\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] \\\\ 3\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] & 4\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] \\\\ \\end{array} \\right]$$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cccccc} 5 & 6 & 7 & 10 & 12 & 14 \\\\ 8 & 9 & 10 & 16 & 18 & 20 \\\\ 15 & 18 & 21 & 20 & 24 & 28 \\\\ 24 & 27 & 30 & 32 & 36 & 40 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{4\\times 6}.$$\n",
    "\n",
    "## 2) Khatri-Rao product (`kr_prod`)\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "Given two matrices $A=\\left( \\boldsymbol{a}_1,\\boldsymbol{a}_2,...,\\boldsymbol{a}_r \\right)\\in\\mathbb{R}^{m\\times r}$ and $B=\\left( \\boldsymbol{b}_1,\\boldsymbol{b}_2,...,\\boldsymbol{b}_r \\right)\\in\\mathbb{R}^{n\\times r}$ with same number of columns, then, the **Khatri-Rao product** (or **column-wise Kronecker product**) between $A$ and $B$ is given as follows,\n",
    "\n",
    "$$A\\odot B=\\left( \\boldsymbol{a}_1\\otimes \\boldsymbol{b}_1,\\boldsymbol{a}_2\\otimes \\boldsymbol{b}_2,...,\\boldsymbol{a}_r\\otimes \\boldsymbol{b}_r \\right)\\in\\mathbb{R}^{(mn)\\times r},$$\n",
    "where the symbol $\\odot$ denotes Khatri-Rao product, and $\\otimes$ denotes Kronecker product.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "If $A=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]=\\left( \\boldsymbol{a}_1,\\boldsymbol{a}_2 \\right) $ and $B=\\left[ \\begin{array}{cc} 5 & 6 \\\\ 7 & 8 \\\\ 9 & 10 \\\\ \\end{array} \\right]=\\left( \\boldsymbol{b}_1,\\boldsymbol{b}_2 \\right) $, then, we have\n",
    "\n",
    "$$A\\odot B=\\left( \\boldsymbol{a}_1\\otimes \\boldsymbol{b}_1,\\boldsymbol{a}_2\\otimes \\boldsymbol{b}_2 \\right) $$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cc} \\left[ \\begin{array}{c} 1 \\\\ 3 \\\\ \\end{array} \\right]\\otimes \\left[ \\begin{array}{c} 5 \\\\ 7 \\\\ 9 \\\\ \\end{array} \\right] & \\left[ \\begin{array}{c} 2 \\\\ 4 \\\\ \\end{array} \\right]\\otimes \\left[ \\begin{array}{c} 6 \\\\ 8 \\\\ 10 \\\\ \\end{array} \\right] \\\\ \\end{array} \\right]$$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cc} 5 & 12 \\\\ 7 & 16 \\\\ 9 & 20 \\\\ 15 & 24 \\\\ 21 & 32 \\\\ 27 & 40 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{6\\times 2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kr_prod(a, b):\n",
    "    return np.einsum('ir, jr -> ijr', a, b).reshape(a.shape[0] * b.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 12]\n",
      " [ 7 16]\n",
      " [ 9 20]\n",
      " [15 24]\n",
      " [21 32]\n",
      " [27 40]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8], [9, 10]])\n",
    "print(kr_prod(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) CP decomposition (`cp_combine`)\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "The CP decomposition factorizes a tensor into a sum of outer products of vectors. For example, for a third-order tensor $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$, the CP decomposition can be written as\n",
    "\n",
    "$$\\hat{\\mathcal{Y}}=\\sum_{s=1}^{r}\\boldsymbol{u}_{s}\\circ\\boldsymbol{v}_{s}\\circ\\boldsymbol{x}_{s},$$\n",
    "or element-wise,\n",
    "\n",
    "$$\\hat{y}_{ijt}=\\sum_{s=1}^{r}u_{is}v_{js}x_{ts},\\forall (i,j,t),$$\n",
    "where vectors $\\boldsymbol{u}_{s}\\in\\mathbb{R}^{m},\\boldsymbol{v}_{s}\\in\\mathbb{R}^{n},\\boldsymbol{x}_{s}\\in\\mathbb{R}^{f}$ are columns of factor matrices $U\\in\\mathbb{R}^{m\\times r},V\\in\\mathbb{R}^{n\\times r},X\\in\\mathbb{R}^{f\\times r}$, respectively. The symbol $\\circ$ denotes vector outer product.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "Given matrices $U=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{2\\times 2}$, $V=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{3\\times 2}$ and $X=\\left[ \\begin{array}{cc} 1 & 5 \\\\ 2 & 6 \\\\ 3 & 7 \\\\ 4 & 8 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{4\\times 2}$, then if $\\hat{\\mathcal{Y}}=\\sum_{s=1}^{r}\\boldsymbol{u}_{s}\\circ\\boldsymbol{v}_{s}\\circ\\boldsymbol{x}_{s}$, then, we have\n",
    "\n",
    "$$\\hat{Y}_1=\\hat{\\mathcal{Y}}(:,:,1)=\\left[ \\begin{array}{ccc} 31 & 42 & 65 \\\\ 63 & 86 & 135 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_2=\\hat{\\mathcal{Y}}(:,:,2)=\\left[ \\begin{array}{ccc} 38 & 52 & 82 \\\\ 78 & 108 & 174 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_3=\\hat{\\mathcal{Y}}(:,:,3)=\\left[ \\begin{array}{ccc} 45 & 62 & 99 \\\\ 93 & 130 & 213 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_4=\\hat{\\mathcal{Y}}(:,:,4)=\\left[ \\begin{array}{ccc} 52 & 72 & 116 \\\\ 108 & 152 & 252 \\\\ \\end{array} \\right].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_combine(U, V, X):\n",
    "    return np.einsum('is, js, ts -> ijt', U, V, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 31  38  45  52]\n",
      "  [ 42  52  62  72]\n",
      "  [ 65  82  99 116]]\n",
      "\n",
      " [[ 63  78  93 108]\n",
      "  [ 86 108 130 152]\n",
      "  [135 174 213 252]]]\n",
      "\n",
      "tensor size:\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "U = np.array([[1, 2], [3, 4]])\n",
    "V = np.array([[1, 3], [2, 4], [5, 6]])\n",
    "X = np.array([[1, 5], [2, 6], [3, 7], [4, 8]])\n",
    "print(cp_combine(U, V, X))\n",
    "print()\n",
    "print('tensor size:')\n",
    "print(cp_combine(U, V, X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Tensor Unfolding (`ten2mat`) and Matrix Folding (`mat2ten`)\n",
    "\n",
    "Using numpy reshape to perform 3rd rank tensor unfold operation. [[**link**](https://stackoverflow.com/questions/49970141/using-numpy-reshape-to-perform-3rd-rank-tensor-unfold-operation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:\n",
      "(3, 2, 4)\n",
      "original tensor:\n",
      "[[[ 1  2  3  4]\n",
      "  [ 3  4  5  6]]\n",
      "\n",
      " [[ 5  6  7  8]\n",
      "  [ 7  8  9 10]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [11 12 13 14]]]\n",
      "\n",
      "(1) mode-1 tensor unfolding:\n",
      "[[ 1  3  2  4  3  5  4  6]\n",
      " [ 5  7  6  8  7  9  8 10]\n",
      " [ 9 11 10 12 11 13 12 14]]\n",
      "\n",
      "(2) mode-2 tensor unfolding:\n",
      "[[ 1  5  9  2  6 10  3  7 11  4  8 12]\n",
      " [ 3  7 11  4  8 12  5  9 13  6 10 14]]\n",
      "\n",
      "(3) mode-3 tensor unfolding:\n",
      "[[ 1  5  9  3  7 11]\n",
      " [ 2  6 10  4  8 12]\n",
      " [ 3  7 11  5  9 13]\n",
      " [ 4  8 12  6 10 14]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[[1, 2, 3, 4], [3, 4, 5, 6]], [[5, 6, 7, 8], [7, 8, 9, 10]], [[9, 10, 11, 12], [11, 12, 13, 14]]])\n",
    "print('tensor size:')\n",
    "print(X.shape)\n",
    "print('original tensor:')\n",
    "print(X)\n",
    "print()\n",
    "print('(1) mode-1 tensor unfolding:')\n",
    "print(ten2mat(X, 0))\n",
    "print()\n",
    "print('(2) mode-2 tensor unfolding:')\n",
    "print(ten2mat(X, 1))\n",
    "print()\n",
    "print('(3) mode-3 tensor unfolding:')\n",
    "print(ten2mat(X, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat2ten(mat, tensor_size, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(tensor_size.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(tensor_size[index]), order = 'F'), 0, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Temporal Regularized Tensor Factorization (TRTF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRTF(dense_tensor, sparse_tensor, U, V, X, theta, time_lags, multi_steps,\n",
    "         lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter):\n",
    "    dim1, dim2, dim3 = dense_tensor.shape\n",
    "    binary_tensor = np.zeros((dim1, dim2, dim3))\n",
    "    position = np.where(sparse_tensor > 0)\n",
    "    binary_tensor[position] = 1\n",
    "    pos = np.where((dense_tensor > 0) & (sparse_tensor == 0))\n",
    "    d = len(time_lags)\n",
    "    rank = U.shape[1]\n",
    "    \n",
    "    for iters in range(maxiter):\n",
    "        var1 = kr_prod(X, V).T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = np.matmul(var2, ten2mat(binary_tensor, 0).T).reshape([rank, rank, dim1]) + np.dstack([lambda_u * np.eye(rank)] * dim1)\n",
    "        var4 = np.matmul(var1, ten2mat(sparse_tensor, 0).T)\n",
    "        for i in range(dim1):\n",
    "            var_Lambda1 = var3[ :, :, i]\n",
    "            inv_var_Lambda1 = np.linalg.inv((var_Lambda1 + var_Lambda1.T)/2)\n",
    "            U[i, :] = np.matmul(inv_var_Lambda1, var4[:, i])\n",
    "\n",
    "        var1 = kr_prod(X, U).T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = np.matmul(var2, ten2mat(binary_tensor, 1).T).reshape([rank, rank, dim2]) + np.dstack([lambda_v * np.eye(rank)] * dim2)\n",
    "        var4 = np.matmul(var1, ten2mat(sparse_tensor, 1).T)\n",
    "        for j in range(dim2):\n",
    "            var_Lambda1 = var3[ :, :, j]\n",
    "            inv_var_Lambda1 = np.linalg.inv((var_Lambda1 + var_Lambda1.T)/2)\n",
    "            V[j, :] = np.matmul(inv_var_Lambda1, var4[:, j])\n",
    "\n",
    "        var1 = kr_prod(V, U).T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = np.matmul(var2, ten2mat(binary_tensor, 2).T).reshape([rank, rank, dim3])\n",
    "        var4 = np.matmul(var1, ten2mat(sparse_tensor, 2).T)\n",
    "        for t in range(dim3):\n",
    "            Mt = np.zeros((rank, rank))\n",
    "            Nt = np.zeros(rank)\n",
    "            if t < max(time_lags):\n",
    "                Pt = np.zeros((rank, rank))\n",
    "                Qt = np.zeros(rank)\n",
    "            else:\n",
    "                Pt = np.eye(rank)\n",
    "                Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "            if t < dim3 - np.min(time_lags):\n",
    "                if t >= np.max(time_lags) and t < dim3 - np.max(time_lags):\n",
    "                    index = list(range(0, d))\n",
    "                else:\n",
    "                    index = list(np.where((t + time_lags >= np.max(time_lags)) & (t + time_lags < dim3)))[0]\n",
    "                for k in index:\n",
    "                    theta0 = theta.copy()\n",
    "                    theta0[k, :] = 0\n",
    "                    Mt = Mt + np.diag(theta[k, :] ** 2);\n",
    "                    Nt = Nt + np.multiply(theta[k, :], (X[t + time_lags[k], :] \n",
    "                                                        - np.einsum('ij, ij -> j', theta0,\n",
    "                                                                    X[t + time_lags[k] - time_lags, :])))\n",
    "                X[t, :] = np.matmul(np.linalg.inv(var3[:, :, t]\n",
    "                                                  + lambda_ar * Pt + lambda_ar * Mt + lambda_ar * eta * np.eye(rank)),\n",
    "                                    (var4[:, t] + lambda_ar * Qt + lambda_ar * Nt))\n",
    "            elif t >= dim3 - np.min(time_lags):\n",
    "                X[t, :] = np.matmul(np.linalg.inv(var3[:, :, t]\n",
    "                                                  + lambda_ar * Pt +\n",
    "                                                  lambda_ar * eta * np.eye(rank)), (var4[:, t] + Qt))\n",
    "\n",
    "        for k in range(d):\n",
    "            var1 = X[np.max(time_lags) - time_lags[k] : dim3 - time_lags[k], :]\n",
    "            var2 = np.linalg.inv(np.diag(np.einsum('ij, ij -> j', var1, var1))\n",
    "                                 + (lambda_theta / lambda_ar) * np.eye(rank))\n",
    "            var3 = np.zeros(rank)\n",
    "            for t in range(np.max(time_lags) - time_lags[k], dim3 - time_lags[k]):\n",
    "                var3 += np.multiply(X[t, :], (X[t + time_lags[k], :] \n",
    "                                              - np.einsum('ij, ij -> j', theta, X[t + time_lags[k] - time_lags, :])\n",
    "                                              + np.multiply(theta[k, :], X[t, :])))\n",
    "            theta[k, :] = np.matmul(var2, var3)\n",
    "            \n",
    "        tensor_hat = cp_combine(U, V, X)\n",
    "        mape = np.sum(np.abs(dense_tensor[pos] - \n",
    "                             tensor_hat[pos])/dense_tensor[pos])/dense_tensor[pos].shape[0]\n",
    "        rmse = np.sqrt(np.sum((dense_tensor[pos] -\n",
    "                               tensor_hat[pos])**2)/dense_tensor[pos].shape[0])\n",
    "        \n",
    "        if (iters + 1) % 100 == 0:\n",
    "            print('Iter: {}'.format(iters + 1))\n",
    "            print('MAPE: {:.6}'.format(mape))\n",
    "            print('RMSE: {:.6}'.format(rmse))\n",
    "            print()\n",
    "            \n",
    "    X_new = np.zeros((dim3 + multi_steps, rank))\n",
    "    X_new[0 : dim3, :] = X.copy()\n",
    "    for t0 in range(multi_steps):\n",
    "        X_new[dim3 + t0, :] = np.einsum('ij, ij -> j', theta, X_new[dim3 + t0 - time_lags, :])        \n",
    "    return cp_combine(U, V, X_new[dim3 : dim3 + multi_steps, :]), U, V, X_new, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-step prediction\n",
    "\n",
    "In the multi-step prediction task, to enable training data for each rolling step informative, we do not apply an online implementation anymore.\n",
    "\n",
    "Involving rolling prediction tasks, there are two crucial inputs:\n",
    "\n",
    "- **`pred_time_steps`**: the number of steps we should forecast, e.g., if we want to forecast time series within 5 days (144 time slots/steps per day) in advance, then the `pred_time_steps` is $5\\times 144=720$;\n",
    "- **`multi_steps`**: the number of steps we should forecast at the current step, e.g., if we want to forecast time series within 2 hours (7 time slots/steps per hour) in advance, then the `multi_stpes` is $2\\times 6=12$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_prediction(dense_tensor, sparse_tensor, pred_time_steps, rank, time_lags, multi_steps,\n",
    "                     lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter):\n",
    "    T = dense_tensor.shape[2]\n",
    "    start_time = T - pred_time_steps\n",
    "    dim1 = dense_tensor.shape[0]\n",
    "    dim2 = dense_tensor.shape[1]\n",
    "    d = time_lags.shape[0]\n",
    "    tensor_hat = np.zeros((dim1, dim2, pred_time_steps))\n",
    "    \n",
    "    for t in range(int(pred_time_steps/multi_steps)):\n",
    "        if t == 0:\n",
    "            ten, U, V, X, theta = TRTF(dense_tensor[:, :, 0 : start_time], sparse_tensor[:, :, 0 : start_time],\n",
    "                                       0.1 * np.random.rand(dim1, rank), 0.1 * np.random.rand(dim2, rank),\n",
    "                                       0.1 * np.random.rand(start_time, rank), 0.1 * np.random.rand(d, rank),\n",
    "                                       time_lags, multi_steps,\n",
    "                                       lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter[0])\n",
    "        else:\n",
    "            ten, U, V, X, theta = TRTF(dense_tensor[:, :, 0 : start_time + t * multi_steps], \n",
    "                                       sparse_tensor[:, :, 0 : start_time + t * multi_steps],\n",
    "                                       U, V, X, theta, time_lags, multi_steps,\n",
    "                                       lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter[1])\n",
    "        tensor_hat[:, :, t * multi_steps : (t + 1) * multi_steps] = ten[:, :, ten.shape[2] - multi_steps : ten.shape[2]]\n",
    "\n",
    "    small_dense_tensor = dense_tensor[:, :, start_time : dense_tensor.shape[2]]\n",
    "    pos = np.where(small_dense_tensor != 0)\n",
    "    final_mape = np.sum(np.abs(small_dense_tensor[pos] - \n",
    "                               tensor_hat[pos])/small_dense_tensor[pos])/small_dense_tensor[pos].shape[0]\n",
    "    final_rmse = np.sqrt(np.sum((small_dense_tensor[pos] - \n",
    "                                 tensor_hat[pos]) ** 2)/small_dense_tensor[pos].shape[0])\n",
    "    print('Final MAPE: {:.6}'.format(final_mape))\n",
    "    print('Final RMSE: {:.6}'.format(final_rmse))\n",
    "    print()\n",
    "    return tensor_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Experiments on New York Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/NYC-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "rm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/rm_tensor.mat')\n",
    "rm_tensor = rm_tensor['rm_tensor']\n",
    "nm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/nm_tensor.mat')\n",
    "nm_tensor = nm_tensor['nm_tensor']\n",
    "\n",
    "missing_rate = 0.0\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(rm_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:78: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Iter: 200\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Final MAPE: 0.868722\n",
      "Final RMSE: 7.13034\n",
      "\n",
      "Running time: 157 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 24 * 7\n",
    "multi_steps = 24\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 24, 24+1, 24+2, 7*24, 7*24+1, 7*24+2])\n",
    "maxiter = np.array([200, 20])\n",
    "theta = 0.1 * np.random.rand(time_lags.shape[0], rank)\n",
    "lambda_u = 500\n",
    "lambda_v = 500\n",
    "lambda_ar = 500\n",
    "eta = 2e-2\n",
    "lambda_theta = 100\n",
    "tensor_hat = multi_prediction(dense_tensor, sparse_tensor, pred_time_steps, rank, time_lags, multi_steps,\n",
    "                              lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/NYC-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "rm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/rm_tensor.mat')\n",
    "rm_tensor = rm_tensor['rm_tensor']\n",
    "nm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/nm_tensor.mat')\n",
    "nm_tensor = nm_tensor['nm_tensor']\n",
    "\n",
    "missing_rate = 0.1\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(rm_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "MAPE: 0.870102\n",
      "RMSE: 6.96969\n",
      "\n",
      "Iter: 200\n",
      "MAPE: 0.858967\n",
      "RMSE: 6.98153\n",
      "\n",
      "Final MAPE: 0.867879\n",
      "Final RMSE: 7.14401\n",
      "\n",
      "Running time: 147 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 24 * 7\n",
    "multi_steps = 24\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 24, 24+1, 24+2, 7*24, 7*24+1, 7*24+2])\n",
    "maxiter = np.array([200, 20])\n",
    "theta = 0.1 * np.random.rand(time_lags.shape[0], rank)\n",
    "lambda_u = 500\n",
    "lambda_v = 500\n",
    "lambda_ar = 500\n",
    "eta = 2e-2\n",
    "lambda_theta = 100\n",
    "tensor_hat = multi_prediction(dense_tensor, sparse_tensor, pred_time_steps, rank, time_lags, multi_steps,\n",
    "                              lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/NYC-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "rm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/rm_tensor.mat')\n",
    "rm_tensor = rm_tensor['rm_tensor']\n",
    "nm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/nm_tensor.mat')\n",
    "nm_tensor = nm_tensor['nm_tensor']\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(rm_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "MAPE: 0.863454\n",
      "RMSE: 7.36969\n",
      "\n",
      "Iter: 200\n",
      "MAPE: 0.864533\n",
      "RMSE: 7.38025\n",
      "\n",
      "Final MAPE: 0.874046\n",
      "Final RMSE: 7.29753\n",
      "\n",
      "Running time: 169 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 24 * 7\n",
    "multi_steps = 24\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 24, 24+1, 24+2, 7*24, 7*24+1, 7*24+2])\n",
    "maxiter = np.array([200, 20])\n",
    "theta = 0.1 * np.random.rand(time_lags.shape[0], rank)\n",
    "lambda_u = 500\n",
    "lambda_v = 500\n",
    "lambda_ar = 500\n",
    "eta = 2e-2\n",
    "lambda_theta = 100\n",
    "tensor_hat = multi_prediction(dense_tensor, sparse_tensor, pred_time_steps, rank, time_lags, multi_steps,\n",
    "                              lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/NYC-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "rm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/rm_tensor.mat')\n",
    "rm_tensor = rm_tensor['rm_tensor']\n",
    "nm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/nm_tensor.mat')\n",
    "nm_tensor = nm_tensor['nm_tensor']\n",
    "\n",
    "missing_rate = 0.1\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        for i3 in range(61):\n",
    "            binary_tensor[i1, i2, i3 * 24 : (i3 + 1) * 24] = np.round(nm_tensor[i1, i2, i3] \n",
    "                                                                      + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "MAPE: 0.908116\n",
      "RMSE: 7.18462\n",
      "\n",
      "Iter: 200\n",
      "MAPE: 0.866683\n",
      "RMSE: 7.17803\n",
      "\n",
      "Final MAPE: 0.871413\n",
      "Final RMSE: 7.1752\n",
      "\n",
      "Running time: 166 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 24 * 7\n",
    "multi_steps = 24\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 24, 24+1, 24+2, 7*24, 7*24+1, 7*24+2])\n",
    "maxiter = np.array([200, 20])\n",
    "theta = 0.1 * np.random.rand(time_lags.shape[0], rank)\n",
    "lambda_u = 500\n",
    "lambda_v = 500\n",
    "lambda_ar = 500\n",
    "eta = 2e-2\n",
    "lambda_theta = 100\n",
    "tensor_hat = multi_prediction(dense_tensor, sparse_tensor, pred_time_steps, rank, time_lags, multi_steps,\n",
    "                              lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/NYC-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "rm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/rm_tensor.mat')\n",
    "rm_tensor = rm_tensor['rm_tensor']\n",
    "nm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/nm_tensor.mat')\n",
    "nm_tensor = nm_tensor['nm_tensor']\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        for i3 in range(61):\n",
    "            binary_tensor[i1, i2, i3 * 24 : (i3 + 1) * 24] = np.round(nm_tensor[i1, i2, i3] \n",
    "                                                                      + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "MAPE: 0.861796\n",
      "RMSE: 7.08837\n",
      "\n",
      "Iter: 200\n",
      "MAPE: 0.855741\n",
      "RMSE: 7.10742\n",
      "\n",
      "Final MAPE: 0.860435\n",
      "Final RMSE: 7.22303\n",
      "\n",
      "Running time: 171 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 24 * 7\n",
    "multi_steps = 24\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 24, 24+1, 24+2, 7*24, 7*24+1, 7*24+2])\n",
    "maxiter = np.array([200, 20])\n",
    "theta = 0.1 * np.random.rand(time_lags.shape[0], rank)\n",
    "lambda_u = 500\n",
    "lambda_v = 500\n",
    "lambda_ar = 500\n",
    "eta = 2e-2\n",
    "lambda_theta = 100\n",
    "tensor_hat = multi_prediction(dense_tensor, sparse_tensor, pred_time_steps, rank, time_lags, multi_steps,\n",
    "                              lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of multi-step prediction with missing values using TRTF:\n",
    "\n",
    "|  scenario |`back_steps`|`rank`|`time_lags`| `maxiter` |       mape |      rmse |\n",
    "|:----------|-----:|-----:|---------:|---------:|-----------:|----------:|\n",
    "|**Original data**| - | 10 | (1,2,3,24,24+1,24+2,7$\\times$24,7$\\times$24+1,7$\\times$24+2) | (200,20) | **0.8687** | **7.13**|\n",
    "|**10%, RM**| - | 10 | (1,2,3,24,24+1,24+2,7$\\times$24,7$\\times$24+1,7$\\times$24+2) | (200,20) | **0.8679** | **7.14**|\n",
    "|**30%, RM**| - | 10 | (1,2,3,24,24+1,24+2,7$\\times$24,7$\\times$24+1,7$\\times$24+2) | (200,20) | **0.8740** | **7.30**|\n",
    "|**10%, NM**| - | 10 | (1,2,3,24,24+1,24+2,7$\\times$24,7$\\times$24+1,7$\\times$24+2) | (200,20) | **0.8714** | **7.18**|\n",
    "|**30%, NM**| - | 10 | (1,2,3,24,24+1,24+2,7$\\times$24,7$\\times$24+1,7$\\times$24+2) | (200,20) | **0.8604** | **7.22**|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
