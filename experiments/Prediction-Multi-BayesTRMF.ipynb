{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Run\n",
    "\n",
    "This notebook is publicly available for any usage at our data imputation project. Please click [**transdim**](https://github.com/xinychen/transdim).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary dependencies. We will make use of `numpy` and `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multivariate_normal as mvnrnd\n",
    "from scipy.stats import wishart\n",
    "from scipy.stats import invwishart\n",
    "from numpy.linalg import inv as inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Matrix Computation Concepts\n",
    "\n",
    "## 1) Kronecker product\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "Given two matrices $A\\in\\mathbb{R}^{m_1\\times n_1}$ and $B\\in\\mathbb{R}^{m_2\\times n_2}$, then, the **Kronecker product** between these two matrices is defined as\n",
    "\n",
    "$$A\\otimes B=\\left[ \\begin{array}{cccc} a_{11}B & a_{12}B & \\cdots & a_{1m_2}B \\\\ a_{21}B & a_{22}B & \\cdots & a_{2m_2}B \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m_11}B & a_{m_12}B & \\cdots & a_{m_1m_2}B \\\\ \\end{array} \\right]$$\n",
    "where the symbol $\\otimes$ denotes Kronecker product, and the size of resulted $A\\otimes B$ is $(m_1m_2)\\times (n_1n_2)$ (i.e., $m_1\\times m_2$ columns and $n_1\\times n_2$ rows).\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "If $A=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]$ and $B=\\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10 \\\\ \\end{array} \\right]$, then, we have\n",
    "\n",
    "$$A\\otimes B=\\left[ \\begin{array}{cc} 1\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] & 2\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] \\\\ 3\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] & 4\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] \\\\ \\end{array} \\right]$$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cccccc} 5 & 6 & 7 & 10 & 12 & 14 \\\\ 8 & 9 & 10 & 16 & 18 & 20 \\\\ 15 & 18 & 21 & 20 & 24 & 28 \\\\ 24 & 27 & 30 & 32 & 36 & 40 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{4\\times 6}.$$\n",
    "\n",
    "## 2) Khatri-Rao product (`kr_prod`)\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "Given two matrices $A=\\left( \\boldsymbol{a}_1,\\boldsymbol{a}_2,...,\\boldsymbol{a}_r \\right)\\in\\mathbb{R}^{m\\times r}$ and $B=\\left( \\boldsymbol{b}_1,\\boldsymbol{b}_2,...,\\boldsymbol{b}_r \\right)\\in\\mathbb{R}^{n\\times r}$ with same number of columns, then, the **Khatri-Rao product** (or **column-wise Kronecker product**) between $A$ and $B$ is given as follows,\n",
    "\n",
    "$$A\\odot B=\\left( \\boldsymbol{a}_1\\otimes \\boldsymbol{b}_1,\\boldsymbol{a}_2\\otimes \\boldsymbol{b}_2,...,\\boldsymbol{a}_r\\otimes \\boldsymbol{b}_r \\right)\\in\\mathbb{R}^{(mn)\\times r}$$\n",
    "where the symbol $\\odot$ denotes Khatri-Rao product, and $\\otimes$ denotes Kronecker product.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "If $A=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]=\\left( \\boldsymbol{a}_1,\\boldsymbol{a}_2 \\right) $ and $B=\\left[ \\begin{array}{cc} 5 & 6 \\\\ 7 & 8 \\\\ 9 & 10 \\\\ \\end{array} \\right]=\\left( \\boldsymbol{b}_1,\\boldsymbol{b}_2 \\right) $, then, we have\n",
    "\n",
    "$$A\\odot B=\\left( \\boldsymbol{a}_1\\otimes \\boldsymbol{b}_1,\\boldsymbol{a}_2\\otimes \\boldsymbol{b}_2 \\right) $$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cc} \\left[ \\begin{array}{c} 1 \\\\ 3 \\\\ \\end{array} \\right]\\otimes \\left[ \\begin{array}{c} 5 \\\\ 7 \\\\ 9 \\\\ \\end{array} \\right] & \\left[ \\begin{array}{c} 2 \\\\ 4 \\\\ \\end{array} \\right]\\otimes \\left[ \\begin{array}{c} 6 \\\\ 8 \\\\ 10 \\\\ \\end{array} \\right] \\\\ \\end{array} \\right]$$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cc} 5 & 12 \\\\ 7 & 16 \\\\ 9 & 20 \\\\ 15 & 24 \\\\ 21 & 32 \\\\ 27 & 40 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{6\\times 2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kr_prod(a, b):\n",
    "    return np.einsum('ir, jr -> ijr', a, b).reshape(a.shape[0] * b.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 12]\n",
      " [ 7 16]\n",
      " [ 9 20]\n",
      " [15 24]\n",
      " [21 32]\n",
      " [27 40]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8], [9, 10]])\n",
    "print(kr_prod(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Computing Covariance Matrix (`cov_mat`)\n",
    "\n",
    "For any matrix $X\\in\\mathbb{R}^{m\\times n}$, `cov_mat` can return a $n\\times n$ covariance matrix for special use in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat(mat):\n",
    "    dim1, dim2 = mat.shape\n",
    "    new_mat = np.zeros((dim2, dim2))\n",
    "    mat_bar = np.mean(mat, axis = 0)\n",
    "    for i in range(dim1):\n",
    "        new_mat += np.einsum('i, j -> ij', mat[i, :] - mat_bar, mat[i, :] - mat_bar)\n",
    "    return new_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Tensor Unfolding (`ten2mat`) and Matrix Folding (`mat2ten`)\n",
    "\n",
    "Using numpy reshape to perform 3rd rank tensor unfold operation. [[**link**](https://stackoverflow.com/questions/49970141/using-numpy-reshape-to-perform-3rd-rank-tensor-unfold-operation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:\n",
      "(3, 2, 4)\n",
      "original tensor:\n",
      "[[[ 1  2  3  4]\n",
      "  [ 3  4  5  6]]\n",
      "\n",
      " [[ 5  6  7  8]\n",
      "  [ 7  8  9 10]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [11 12 13 14]]]\n",
      "\n",
      "(1) mode-1 tensor unfolding:\n",
      "[[ 1  3  2  4  3  5  4  6]\n",
      " [ 5  7  6  8  7  9  8 10]\n",
      " [ 9 11 10 12 11 13 12 14]]\n",
      "\n",
      "(2) mode-2 tensor unfolding:\n",
      "[[ 1  5  9  2  6 10  3  7 11  4  8 12]\n",
      " [ 3  7 11  4  8 12  5  9 13  6 10 14]]\n",
      "\n",
      "(3) mode-3 tensor unfolding:\n",
      "[[ 1  5  9  3  7 11]\n",
      " [ 2  6 10  4  8 12]\n",
      " [ 3  7 11  5  9 13]\n",
      " [ 4  8 12  6 10 14]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[[1, 2, 3, 4], [3, 4, 5, 6]], \n",
    "              [[5, 6, 7, 8], [7, 8, 9, 10]], \n",
    "              [[9, 10, 11, 12], [11, 12, 13, 14]]])\n",
    "print('tensor size:')\n",
    "print(X.shape)\n",
    "print('original tensor:')\n",
    "print(X)\n",
    "print()\n",
    "print('(1) mode-1 tensor unfolding:')\n",
    "print(ten2mat(X, 0))\n",
    "print()\n",
    "print('(2) mode-2 tensor unfolding:')\n",
    "print(ten2mat(X, 1))\n",
    "print()\n",
    "print('(3) mode-3 tensor unfolding:')\n",
    "print(ten2mat(X, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat2ten(mat, tensor_size, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(tensor_size.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(tensor_size[index]), order = 'F'), 0, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Bayesian Temporal Regularized Matrix Factorization (BayesTRMF)\n",
    "\n",
    "Implementing BayesTRMF involves learning three main components:\n",
    "\n",
    "- spatial factor matrix\n",
    "- temporal factor matrix\n",
    "- coefficient matrices of AR\n",
    "\n",
    "In this implementation, we have included Gibbs sampling over these main components and other parameters/hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BayesTRMF(dense_mat, sparse_mat, init, rank, time_lags, multi_steps, maxiter1, maxiter2):\n",
    "    \"\"\"Bayesian Temporal Regularized Matrix Factorization, BayesTRMF.\"\"\"\n",
    "    W = init[\"W\"]\n",
    "    X = init[\"X\"]\n",
    "    theta = init[\"theta\"]\n",
    "    \n",
    "    d = theta.shape[0]\n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    pos = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "    position = np.where(sparse_mat != 0)\n",
    "    binary_mat = np.zeros((dim1, dim2))\n",
    "    binary_mat[position] = 1\n",
    "    \n",
    "    beta0 = 1\n",
    "    nu0 = rank\n",
    "    mu0 = np.zeros((rank))\n",
    "    W0 = np.eye(rank)\n",
    "    tau = 1\n",
    "    alpha = 1e-6\n",
    "    beta = 1e-6\n",
    "    \n",
    "    W_plus = np.zeros((dim1, rank))\n",
    "    X_plus = np.zeros((dim2, rank))\n",
    "    theta_plus = np.zeros((d, rank))\n",
    "    for iters in range(maxiter1):\n",
    "        W_bar = np.mean(W, axis = 0)\n",
    "        var_mu_hyper = (dim1 * W_bar + beta0 * mu0)/(dim1 + beta0)\n",
    "        var_W_hyper = inv(inv(W0) + cov_mat(W) + dim1 * beta0/(dim1 + beta0) \n",
    "                          * np.outer(W_bar - mu0, W_bar - mu0))\n",
    "        var_W_hyper = (var_W_hyper + var_W_hyper.T)/2\n",
    "        var_Lambda_hyper = wishart(df = dim1 + nu0, scale = var_W_hyper, seed = None).rvs()\n",
    "        var_mu_hyper = mvnrnd(var_mu_hyper, inv((dim1 + beta0) * var_Lambda_hyper))\n",
    "        \n",
    "        var1 = X.T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = (tau * np.matmul(var2, binary_mat.T).reshape([rank, rank, dim1]) \n",
    "                + np.dstack([var_Lambda_hyper] * dim1))\n",
    "        var4 = (tau * np.matmul(var1, sparse_mat.T)\n",
    "                + np.dstack([np.matmul(var_Lambda_hyper, var_mu_hyper)] * dim1)[0, :, :])\n",
    "        for i in range(dim1):\n",
    "            var_Lambda = var3[:, :, i]\n",
    "            inv_var_Lambda = inv((var_Lambda + var_Lambda.T)/2)\n",
    "            var_mu = np.matmul(inv_var_Lambda, var4[:, i])\n",
    "            W[i, :] = mvnrnd(var_mu, inv_var_Lambda)\n",
    "        if iters + 1 > maxiter1 - maxiter2:\n",
    "            W_plus += W\n",
    "        \n",
    "        mat0 = X[0 : np.max(time_lags), :]\n",
    "        mat = np.matmul(mat0.T, mat0)\n",
    "        new_mat = np.zeros((dim2 - np.max(time_lags), rank))\n",
    "        for t in range(dim2 - np.max(time_lags)):\n",
    "            new_mat[t, :] = (X[t + np.max(time_lags), :]\n",
    "                             - np.einsum('ij, ij -> j', theta, X[t + np.max(time_lags) - time_lags, :]))\n",
    "        mat += np.matmul(new_mat.T, new_mat)\n",
    "        var_W_hyper = inv(inv(W0) + mat)\n",
    "        var_W_hyper = (var_W_hyper + var_W_hyper.T)/2\n",
    "        Lambda_x = wishart(df = dim2 + nu0, scale = var_W_hyper, seed = None).rvs()\n",
    "        \n",
    "        var1 = W.T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = tau * np.matmul(var2, binary_mat).reshape([rank, rank, dim2]) + np.dstack([Lambda_x] * dim2)\n",
    "        var4 = tau * np.matmul(var1, sparse_mat)\n",
    "        for t in range(dim2):\n",
    "            Mt = np.zeros((rank, rank))\n",
    "            Nt = np.zeros(rank)\n",
    "            if t < np.max(time_lags):\n",
    "                Qt = np.zeros(rank)\n",
    "            else:\n",
    "                Qt = np.matmul(Lambda_x, np.einsum('ij, ij -> j', theta, X[t - time_lags, :]))\n",
    "            if t < dim2 - np.min(time_lags):\n",
    "                if t >= np.max(time_lags) and t < dim2 - np.max(time_lags):\n",
    "                    index = list(range(0, d))\n",
    "                else:\n",
    "                    index = list(np.where((t + time_lags >= np.max(time_lags)) & (t + time_lags < dim2)))[0]\n",
    "                for k in index:\n",
    "                    Ak = theta[k, :]\n",
    "                    Mt += np.multiply(np.outer(Ak, Ak), Lambda_x)\n",
    "                    theta0 = theta.copy()\n",
    "                    theta0[k, :] = 0\n",
    "                    var5 = (X[t + time_lags[k], :] \n",
    "                            - np.einsum('ij, ij -> j', theta0, X[t + time_lags[k] - time_lags, :]))\n",
    "                    Nt += np.matmul(np.matmul(np.diag(Ak), Lambda_x), var5)\n",
    "            var_mu = var4[:, t] + Nt + Qt\n",
    "            var_Lambda = var3[:, :, t] + Mt\n",
    "            inv_var_Lambda = inv((var_Lambda + var_Lambda.T)/2)\n",
    "            X[t, :] = mvnrnd(np.matmul(inv_var_Lambda, var_mu), inv_var_Lambda)\n",
    "        if iters + 1 > maxiter1 - maxiter2:\n",
    "            X_plus += X\n",
    "            \n",
    "        mat_hat = np.matmul(W, X.T)\n",
    "        rmse = np.sqrt(np.sum((dense_mat[pos] - mat_hat[pos]) ** 2)/dense_mat[pos].shape[0])\n",
    "        \n",
    "        tau = np.random.gamma(alpha + 0.5 * sparse_mat[position].shape[0], \n",
    "                              1/(beta + 0.5 * np.sum((sparse_mat - mat_hat)[position] ** 2)))\n",
    "\n",
    "        theta_bar = np.mean(theta, axis = 0)\n",
    "        var_mu_hyper = (d * theta_bar + beta0 * mu0)/(d + beta0)\n",
    "        var_W_hyper = inv(inv(W0) + cov_mat(theta) + d * beta0/(d + beta0)\n",
    "                          * np.outer(theta_bar - mu0, theta_bar - mu0))\n",
    "        var_W_hyper = (var_W_hyper + var_W_hyper.T)/2\n",
    "        var_Lambda_hyper = wishart(df = d + nu0, scale = var_W_hyper, seed = None).rvs()\n",
    "        var_mu_hyper = mvnrnd(var_mu_hyper, inv((d + beta0) * var_Lambda_hyper))\n",
    "        \n",
    "        for k in range(d):\n",
    "            theta0 = theta.copy()\n",
    "            theta0[k, :] = 0\n",
    "            mat0 = np.zeros((dim2 - np.max(time_lags), rank))\n",
    "            for L in range(d):\n",
    "                mat0 += np.matmul(X[np.max(time_lags) - time_lags[L] : dim2 - time_lags[L], :], \n",
    "                                  np.diag(theta0[L, :]))\n",
    "            VarPi = X[np.max(time_lags) : dim2, :] - mat0\n",
    "            var1 = np.zeros((rank, rank))\n",
    "            var2 = np.zeros(rank)\n",
    "            for t in range(np.max(time_lags), dim2):\n",
    "                B = X[t - time_lags[k], :]\n",
    "                var1 += np.multiply(np.outer(B, B), Lambda_x)\n",
    "                var2 += np.matmul(np.matmul(np.diag(B), Lambda_x), VarPi[t - np.max(time_lags), :])\n",
    "            var_Lambda = var1 + var_Lambda_hyper\n",
    "            inv_var_Lambda = inv((var_Lambda + var_Lambda.T)/2)\n",
    "            var_mu = np.matmul(inv_var_Lambda, var2 + np.matmul(var_Lambda_hyper, var_mu_hyper))\n",
    "            theta[k, :] = mvnrnd(var_mu, inv_var_Lambda)\n",
    "        if iters + 1 > maxiter1 - maxiter2:\n",
    "            theta_plus += theta\n",
    "\n",
    "        if (iters + 1) % 200 == 0 and iters < maxiter1 - maxiter2:\n",
    "            print('Iter: {}'.format(iters + 1))\n",
    "            print('RMSE: {:.6}'.format(rmse))\n",
    "            print()\n",
    "\n",
    "    W = W_plus/maxiter2\n",
    "    theta = theta_plus/maxiter2\n",
    "    X_new = np.zeros((dim2 + multi_steps, rank))\n",
    "    X_new[0 : dim2, :] = X_plus/maxiter2\n",
    "    for t0 in range(multi_steps):\n",
    "        X_new[dim2 + t0, :] = np.einsum('ij, ij -> j', theta, X_new[dim2 + t0 - time_lags, :])\n",
    "    if maxiter1 >= 100:\n",
    "        final_mape = np.sum(np.abs(dense_mat[pos] - mat_hat[pos])/dense_mat[pos])/dense_mat[pos].shape[0]\n",
    "        final_rmse = np.sqrt(np.sum((dense_mat[pos] - mat_hat[pos]) ** 2)/dense_mat[pos].shape[0])\n",
    "        print('Imputation MAPE: {:.6}'.format(final_mape))\n",
    "        print('Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "        print()\n",
    "    \n",
    "    return np.matmul(W, X_new[dim2 : dim2 + multi_steps, :].T), W, X_new, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-step prediction\n",
    "\n",
    "In the multi-step prediction task, to enable training data for each rolling step informative, we do not apply an online implementation anymore.\n",
    "\n",
    "Involving rolling prediction tasks, there are two crucial inputs:\n",
    "\n",
    "- **`pred_time_steps`**: the number of steps we should forecast, e.g., if we want to forecast time series within 5 days (144 time slots/steps per day) in advance, then the `pred_time_steps` is $5\\times 144=720$;\n",
    "- **`multi_steps`**: the number of steps we should forecast at the current step, e.g., if we want to forecast time series within 2 hours (7 time slots/steps per hour) in advance, then the `multi_stpes` is $2\\times 6=12$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter):\n",
    "    T = dense_mat.shape[1]\n",
    "    start_time = T - pred_time_steps\n",
    "    dim1 = dense_mat.shape[0]\n",
    "    d = time_lags.shape[0]\n",
    "    mat_hat = np.zeros((dim1, pred_time_steps))\n",
    "    \n",
    "    for t in range(int(pred_time_steps/multi_steps)):\n",
    "        if t == 0:\n",
    "            init = {\"W\": 0.1 * np.random.rand(dim1, rank), \"X\": 0.1 * np.random.rand(start_time, rank),\n",
    "                   \"theta\": 0.1 * np.random.rand(d, rank)}\n",
    "            mat, W, X, theta = BayesTRMF(dense_mat[:, 0 : start_time], \n",
    "                                         sparse_mat[:, 0 : start_time], \n",
    "                                         init, rank, time_lags, multi_steps, maxiter[0], maxiter[1])\n",
    "        else:\n",
    "            init = {\"W\": W, \"X\": X, \"theta\": theta}\n",
    "            mat, W, X, theta = BayesTRMF(dense_mat[:, 0 : start_time + t * multi_steps], \n",
    "                                         sparse_mat[:, 0 : start_time + t * multi_steps], \n",
    "                                         init, rank, time_lags, multi_steps, maxiter[2], maxiter[3])\n",
    "        mat_hat[:, t * multi_steps : (t + 1) * multi_steps] = mat[:, mat.shape[1] - multi_steps : mat.shape[1]]\n",
    "\n",
    "    small_dense_mat = dense_mat[:, start_time : dense_mat.shape[1]]\n",
    "    pos = np.where(small_dense_mat != 0)\n",
    "    final_mape = np.sum(np.abs(small_dense_mat[pos] - \n",
    "                               mat_hat[pos])/small_dense_mat[pos])/small_dense_mat[pos].shape[0]\n",
    "    final_rmse = np.sqrt(np.sum((small_dense_mat[pos] - \n",
    "                                 mat_hat[pos]) ** 2)/small_dense_mat[pos].shape[0])\n",
    "    print('Final MAPE: {:.6}'.format(final_mape))\n",
    "    print('Final RMSE: {:.6}'.format(final_rmse))\n",
    "    print()\n",
    "    return mat_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Data Organization\n",
    "\n",
    "## 1) Matrix Structure\n",
    "\n",
    "We consider a dataset of $m$ discrete time series $\\boldsymbol{y}_{i}\\in\\mathbb{R}^{f},i\\in\\left\\{1,2,...,m\\right\\}$. The time series may have missing elements. We express spatio-temporal dataset as a matrix $Y\\in\\mathbb{R}^{m\\times f}$ with $m$ rows (e.g., locations) and $f$ columns (e.g., discrete time intervals),\n",
    "\n",
    "$$Y=\\left[ \\begin{array}{cccc} y_{11} & y_{12} & \\cdots & y_{1f} \\\\ y_{21} & y_{22} & \\cdots & y_{2f} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_{m1} & y_{m2} & \\cdots & y_{mf} \\\\ \\end{array} \\right]\\in\\mathbb{R}^{m\\times f}.$$\n",
    "\n",
    "## 2) Tensor Structure\n",
    "\n",
    "We consider a dataset of $m$ discrete time series $\\boldsymbol{y}_{i}\\in\\mathbb{R}^{nf},i\\in\\left\\{1,2,...,m\\right\\}$. The time series may have missing elements. We partition each time series into intervals of predifined length $f$. We express each partitioned time series as a matrix $Y_{i}$ with $n$ rows (e.g., days) and $f$ columns (e.g., discrete time intervals per day),\n",
    "\n",
    "$$Y_{i}=\\left[ \\begin{array}{cccc} y_{11} & y_{12} & \\cdots & y_{1f} \\\\ y_{21} & y_{22} & \\cdots & y_{2f} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_{n1} & y_{n2} & \\cdots & y_{nf} \\\\ \\end{array} \\right]\\in\\mathbb{R}^{n\\times f},i=1,2,...,m,$$\n",
    "\n",
    "therefore, the resulting structure is a tensor $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Experiments on Guangzhou Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.0\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(random_tensor + 0.5 - missing_rate).reshape([random_tensor.shape[0], \n",
    "                                                                   random_tensor.shape[1] \n",
    "                                                                   * random_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:91: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:137: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:138: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Final MAPE: 0.170305\n",
      "Final RMSE: 6.37012\n",
      "\n",
      "Running time: 1343 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 144 * 5\n",
    "multi_steps = 144\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 144, 144+1, 144+2, 7*144, 7*144+1, 7*144+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(random_tensor + 0.5 - missing_rate).reshape([random_tensor.shape[0], \n",
    "                                                                   random_tensor.shape[1] \n",
    "                                                                   * random_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.100318\n",
      "Imputation RMSE: 4.22255\n",
      "\n",
      "Final MAPE: 0.187777\n",
      "Final RMSE: 7.10324\n",
      "\n",
      "Running time: 1420 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 144 * 5\n",
    "multi_steps = 144\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 144, 144+1, 144+2, 7*144, 7*144+1, 7*144+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(random_tensor + 0.5 - missing_rate).reshape([random_tensor.shape[0], \n",
    "                                                                   random_tensor.shape[1] \n",
    "                                                                   * random_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.101335\n",
      "Imputation RMSE: 4.26563\n",
      "\n",
      "Final MAPE: 0.1801\n",
      "Final RMSE: 6.67925\n",
      "\n",
      "Running time: 1285 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 144 * 5\n",
    "multi_steps = 144\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 144, 144+1, 144+2, 7*144, 7*144+1, 7*144+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1,i2,:] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] \n",
    "                                    * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.10328\n",
      "Imputation RMSE: 4.34547\n",
      "\n",
      "Final MAPE: 0.191536\n",
      "Final RMSE: 7.43985\n",
      "\n",
      "Running time: 1279 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 144 * 5\n",
    "multi_steps = 144\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 144, 144+1, 144+2, 7*144, 7*144+1, 7*144+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1,i2,:] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] \n",
    "                                    * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.105568\n",
      "Imputation RMSE: 4.49288\n",
      "\n",
      "Final MAPE: 0.20942\n",
      "Final RMSE: 8.15881\n",
      "\n",
      "Running time: 1285 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 144 * 5\n",
    "multi_steps = 144\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 144, 144+1, 144+2, 7*144, 7*144+1, 7*144+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of multi-step prediction with missing values using BayesTRMF:\n",
    "\n",
    "|  scenario |`rank`|`time_lags`| `maxiter` |       mape |      rmse |\n",
    "|:----------|-----:|---------:|---------:|-----------:|----------:|\n",
    "|**Original data**| 10 | (1,2,3,144,144+1,144+2,7$\\times$144,7$\\times$144+1,7$\\times$144+2) | (200,100,20,10) | **0.1703** | **6.37**|\n",
    "|**20%, RM**| 10 | (1,2,3,144,144+1,144+2,7$\\times$144,7$\\times$144+1,7$\\times$144+2) | (200,100,20,10) | **0.1878** | **7.10**|\n",
    "|**40%, RM**| 10 | (1,2,3,144,144+1,144+2,7$\\times$144,7$\\times$144+1,7$\\times$144+2) | (200,100,20,10) | **0.1801** | **6.68**|\n",
    "|**20%, NM**| 10 | (1,2,3,144,144+1,144+2,7$\\times$144,7$\\times$144+1,7$\\times$144+2) | (200,100,20,10) | **0.1915** | **7.44**|\n",
    "|**40%, NM**| 10 | (1,2,3,144,144+1,144+2,7$\\times$144,7$\\times$144+1,7$\\times$144+2) | (200,100,20,10) | **0.2094** | **8.16**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Experiments on Birmingham Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.0\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(random_tensor + 0.5 - missing_rate).reshape([random_tensor.shape[0], \n",
    "                                                                   random_tensor.shape[1] \n",
    "                                                                   * random_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:91: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:137: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:138: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Final MAPE: 0.344887\n",
      "Final RMSE: 292.101\n",
      "\n",
      "Running time: 231 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 18 * 7\n",
    "multi_steps = 18\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 18, 18+1, 18+2, 7*18, 7*18+1, 7*18+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.1\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(random_tensor + 0.5 - missing_rate).reshape([random_tensor.shape[0], \n",
    "                                                                   random_tensor.shape[1] \n",
    "                                                                   * random_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.0929391\n",
      "Imputation RMSE: 30.2429\n",
      "\n",
      "Final MAPE: 0.403732\n",
      "Final RMSE: 339.974\n",
      "\n",
      "Running time: 230 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 18 * 7\n",
    "multi_steps = 18\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 18, 18+1, 18+2, 7*18, 7*18+1, 7*18+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.3\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(random_tensor + 0.5 - missing_rate).reshape([random_tensor.shape[0], \n",
    "                                                                   random_tensor.shape[1] \n",
    "                                                                   * random_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.0956688\n",
      "Imputation RMSE: 35.1675\n",
      "\n",
      "Final MAPE: 0.260374\n",
      "Final RMSE: 183.628\n",
      "\n",
      "Running time: 230 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 18 * 7\n",
    "multi_steps = 18\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 18, 18+1, 18+2, 7*18, 7*18+1, 7*18+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.1\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1,i2,:] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.134775\n",
      "Imputation RMSE: 31.877\n",
      "\n",
      "Final MAPE: 0.386044\n",
      "Final RMSE: 326.774\n",
      "\n",
      "Running time: 231 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 18 * 7\n",
    "multi_steps = 18\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 18, 18+1, 18+2, 7*18, 7*18+1, 7*18+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.3\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1,i2,:] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.151767\n",
      "Imputation RMSE: 50.6652\n",
      "\n",
      "Final MAPE: 0.3553\n",
      "Final RMSE: 276.107\n",
      "\n",
      "Running time: 229 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 18 * 7\n",
    "multi_steps = 18\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 18, 18+1, 18+2, 7*18, 7*18+1, 7*18+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of multi-step rolling prediction with missing values using BayesTRMF:\n",
    "\n",
    "|  scenario |`rank`|`time_lags`| `maxiter` |       mape |      rmse |\n",
    "|:----------|-----:|---------:|---------:|-----------:|----------:|\n",
    "|**Original data**| 10 | (1,2,3,18,18+1,18+2,7$\\times$18,7$\\times$18+1,7$\\times$18+2) | (200,100,20,10) | **0.3449** | **292.10**|\n",
    "|**10%, RM**| 10 | (1,2,3,18,18+1,18+2,7$\\times$18,7$\\times$18+1,7$\\times$18+2) | (200,100,20,10) | **0.4037** | **339.97**|\n",
    "|**30%, RM**| 10 | (1,2,3,18,18+1,18+2,7$\\times$18,7$\\times$18+1,7$\\times$18+2) | (200,100,20,10) | **0.2604** | **183.63**|\n",
    "|**10%, NM**| 10 | (1,2,3,18,18+1,18+2,7$\\times$18,7$\\times$18+1,7$\\times$18+2) | (200,100,20,10) | **0.3860** | **326.77**|\n",
    "|**30%, NM**| 10 | (1,2,3,18,18+1,18+2,7$\\times$18,7$\\times$18+1,7$\\times$18+2) | (200,100,20,10) | **0.3553** | **276.11**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Experiments on Hangzhou Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.0\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(random_tensor + 0.5 - missing_rate).reshape([random_tensor.shape[0], \n",
    "                                                                   random_tensor.shape[1] \n",
    "                                                                   * random_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:91: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:137: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:138: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Final MAPE: 0.405368\n",
      "Final RMSE: 46.8406\n",
      "\n",
      "Running time: 301 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 108 * 5\n",
    "multi_steps = 108\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 108, 108 + 1, 108 + 2, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(random_tensor + 0.5 - missing_rate).reshape([random_tensor.shape[0], \n",
    "                                                                   random_tensor.shape[1] \n",
    "                                                                   * random_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.348635\n",
      "Imputation RMSE: 49.3177\n",
      "\n",
      "Final MAPE: 0.300895\n",
      "Final RMSE: 41.3133\n",
      "\n",
      "Running time: 303 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 108 * 5\n",
    "multi_steps = 108\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 108, 108 + 1, 108 + 2, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(random_tensor + 0.5 - missing_rate).reshape([random_tensor.shape[0], \n",
    "                                                                   random_tensor.shape[1] \n",
    "                                                                   * random_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.387581\n",
      "Imputation RMSE: 53.7501\n",
      "\n",
      "Final MAPE: 0.313074\n",
      "Final RMSE: 43.3901\n",
      "\n",
      "Running time: 302 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 108 * 5\n",
    "multi_steps = 108\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 108, 108 + 1, 108 + 2, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1,i2,:] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] \n",
    "                                    * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.427486\n",
      "Imputation RMSE: 81.6562\n",
      "\n",
      "Final MAPE: 0.338244\n",
      "Final RMSE: 51.8047\n",
      "\n",
      "Running time: 302 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 108 * 5\n",
    "multi_steps = 108\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 108, 108 + 1, 108 + 2, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1,i2,:] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] \n",
    "                                    * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.45075\n",
      "Imputation RMSE: 73.8157\n",
      "\n",
      "Final MAPE: 0.412028\n",
      "Final RMSE: 59.5594\n",
      "\n",
      "Running time: 302 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 108 * 5\n",
    "multi_steps = 108\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 108, 108 + 1, 108 + 2, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of multi-step rolling prediction with missing values using BayesTRMF:\n",
    "\n",
    "|  scenario |`rank`|`time_lags`| `maxiter` |       mape |      rmse |\n",
    "|:----------|-----:|---------:|---------:|-----------:|----------:|\n",
    "|**Original data**| 10 | (1,2,3,108,108+1,108+2,7$\\times$108,7$\\times$108+1,7$\\times$108+2) | (200,100,20,10) | **0.4054** | **46.84**|\n",
    "|**20%, RM**| 10 | (1,2,3,108,108+1,108+2,7$\\times$108,7$\\times$108+1,7$\\times$108+2) | (200,100,20,10) | **0.3009** | **41.31**|\n",
    "|**40%, RM**| 10 | (1,2,3,108,108+1,108+2,7$\\times$108,7$\\times$108+1,7$\\times$108+2) | (200,100,20,10) | **0.3131** | **43.39**|\n",
    "|**20%, NM**| 10 | (1,2,3,108,108+1,108+2,7$\\times$108,7$\\times$108+1,7$\\times$108+2) | (200,100,20,10) | **0.3382** | **51.80**|\n",
    "|**40%, NM**| 10 | (1,2,3,108,108+1,108+2,7$\\times$108,7$\\times$108+1,7$\\times$108+2) | (200,100,20,10) | **0.4120** | **59.56**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Experiments on Seattle Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "\n",
    "missing_rate = 0.0\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(RM_mat + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.0898133\n",
      "Imputation RMSE: 5.07589\n",
      "\n",
      "Final MAPE: 0.242515\n",
      "Final RMSE: 13.3104\n",
      "\n",
      "Running time: 1020 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 288 * 5\n",
    "multi_steps = 288\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 288, 288+1, 288+2, 7*288, 7*288+1, 7*288+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "\n",
    "missing_rate = 0.2\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(RM_mat + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.0893588\n",
      "Imputation RMSE: 5.1227\n",
      "\n",
      "Final MAPE: 0.21182\n",
      "Final RMSE: 11.4088\n",
      "\n",
      "Running time: 1022 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 288 * 5\n",
    "multi_steps = 288\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 288, 288+1, 288+2, 7*288, 7*288+1, 7*288+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "\n",
    "missing_rate = 0.4\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(RM_mat + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.0910282\n",
      "Imputation RMSE: 5.19597\n",
      "\n",
      "Final MAPE: 0.198036\n",
      "Final RMSE: 10.4839\n",
      "\n",
      "Running time: 1019 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 288 * 5\n",
    "multi_steps = 288\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 288, 288+1, 288+2, 7*288, 7*288+1, 7*288+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "NM_mat = pd.read_csv('../datasets/Seattle-data-set/NM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "NM_mat = NM_mat.values\n",
    "\n",
    "missing_rate = 0.2\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 28, 288))\n",
    "for i1 in range(binary_tensor.shape[0]):\n",
    "    for i2 in range(binary_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(NM_mat[i1, i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.0964484\n",
      "Imputation RMSE: 5.43151\n",
      "\n",
      "Final MAPE: 0.237014\n",
      "Final RMSE: 12.871\n",
      "\n",
      "Running time: 1017 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 288 * 5\n",
    "multi_steps = 288\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 288, 288+1, 288+2, 7*288, 7*288+1, 7*288+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "NM_mat = pd.read_csv('../datasets/Seattle-data-set/NM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "NM_mat = NM_mat.values\n",
    "\n",
    "missing_rate = 0.4\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 28, 288))\n",
    "for i1 in range(binary_tensor.shape[0]):\n",
    "    for i2 in range(binary_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(NM_mat[i1, i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.0973556\n",
      "Imputation RMSE: 5.51872\n",
      "\n",
      "Final MAPE: 0.232298\n",
      "Final RMSE: 12.5847\n",
      "\n",
      "Running time: 1017 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 288 * 5\n",
    "multi_steps = 288\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 3, 288, 288+1, 288+2, 7*288, 7*288+1, 7*288+2])\n",
    "maxiter = np.array([200, 100, 20, 10])\n",
    "small_dense_mat = dense_mat[:, dense_mat.shape[1] - pred_time_steps : dense_mat.shape[1]]\n",
    "mat_hat = multi_prediction(dense_mat, sparse_mat, pred_time_steps, multi_steps, rank, time_lags, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of short-term rolling prediction with missing values using BayesTRMF:\n",
    "\n",
    "|  scenario |`rank`|`time_lags`| `maxiter` |       mape |      rmse |\n",
    "|:----------|-----:|---------:|---------:|-----------:|----------:|\n",
    "|**Original data**| 10 | (1,2,3,288,288+1,288+2,7$\\times$288,7$\\times$288+1,7$\\times$288+2) | (200,100,20,10) | **0.2425** | **13.31**|\n",
    "|**20%, RM**| 10 | (1,2,3,288,288+1,288+2,7$\\times$288,7$\\times$288+1,7$\\times$288+2) | (200,100,20,10) | **0.2118** | **11.41**|\n",
    "|**40%, RM**| 10 | (1,2,3,288,288+1,288+2,7$\\times$288,7$\\times$288+1,7$\\times$288+2) | (200,100,20,10) | **0.1980** | **10.48**|\n",
    "|**20%, NM**| 10 | (1,2,3,288,288+1,288+2,7$\\times$288,7$\\times$288+1,7$\\times$288+2) | (200,100,20,10) | **0.2370** | **12.87**|\n",
    "|**40%, NM**| 10 | (1,2,3,288,288+1,288+2,7$\\times$288,7$\\times$288+1,7$\\times$288+2) | (200,100,20,10) | **0.2323** | **12.58**|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
