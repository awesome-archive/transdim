{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: What Does `TRTF` Look Like?\n",
    "\n",
    "**Tensor factorization**for any given tensor $\\mathcal{Y}\\in\\mathbb{R}^{M\\times N\\times T}$ with rank $R$:\n",
    "$$y_{ijt}\\approx\\sum_{r=1}^{R}u_{ir}v_{jr}x_{tr}\\\\=\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)^{\\top}\\boldsymbol{x}_{t}\\\\=\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)^{\\top}\\boldsymbol{v}_{j}\\\\=\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)^{\\top}\\boldsymbol{u}_{i}$$\n",
    "\n",
    "**Temporal regularized tensor factorization (TRMF)**:\n",
    "$$\\min_{U,V,X}~~\\sum_{(i,j,t)\\in\\Omega}\\left(y_{ijt}-\\sum_{r=1}^{R}u_{ir}v_{jr}x_{tr}\\right)^2\\\\\n",
    "+\\lambda_{u}\\sum_{i=1}^{M}\\left\\|\\boldsymbol{u}_{i}\\right\\|_{2}^{2}+\\lambda_{v}\\sum_{j=1}^{N}\\left\\|\\boldsymbol{v}_{j}\\right\\|_{2}^{2}+\\lambda_{x}\\sum_{t=1}^{T}\\left\\|\\boldsymbol{x}_{t}\\right\\|_{2}^{2}\\\\\n",
    "+\\lambda_{ar}\\sum_{t=h_d+1}^{T}\\left\\|\\boldsymbol{x}_{t}-\\sum_{k=1}^{d}\\boldsymbol{\\theta}_{k}\\circledast\\boldsymbol{x}_{t-h_k}\\right\\|_{2}^{2}+\\lambda_{\\theta}\\sum_{l\\in\\mathcal{L}}\\left\\|\\boldsymbol{\\theta}_{l}\\right\\|_{2}^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Alternative Minimization for `TRTF`\n",
    "\n",
    "## Optimizing $\\boldsymbol{u}_{i},i\\in\\left\\{1,2,...,M\\right\\}$:\n",
    "\n",
    "**Optimization problem**:\n",
    "$$\\min_{\\boldsymbol{u}_{i}}\\sum_{j,t:(i,j,t)\\in\\Omega}\\left(y_{ijt}-\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)^{\\top}\\boldsymbol{u}_{i}\\right)^{\\top}\\left(y_{ijt}-\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)^{\\top}\\boldsymbol{u}_{i}\\right)+\\lambda_{u}\\boldsymbol{u}_{i}^{\\top}\\boldsymbol{u}_{i}$$\n",
    "\n",
    "**Solution**:\n",
    "$$\\boldsymbol{u}_{i}\\Leftarrow\\left(\\sum_{j,t:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)^{\\top}+\\lambda_{u}I_{R}\\right)^{-1}\\sum_{j,t:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)y_{ijt}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing $\\boldsymbol{v}_{j},j\\in\\left\\{1,2,...,N\\right\\}$:\n",
    "\n",
    "**Optimization problem**:\n",
    "$$\\min_{\\boldsymbol{v}_{j}}\\sum_{i,t:(i,j,t)\\in\\Omega}\\left(y_{ijt}-\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)^{\\top}\\boldsymbol{v}_{j}\\right)^{\\top}\\left(y_{ijt}-\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)^{\\top}\\boldsymbol{v}_{j}\\right)+\\lambda_{v}\\boldsymbol{v}_{j}^{\\top}\\boldsymbol{v}_{j}$$\n",
    "\n",
    "**Solution**:\n",
    "$$\\boldsymbol{v}_{j}\\Leftarrow\\left(\\sum_{i,t:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)^{\\top}+\\lambda_{v}I_{R}\\right)^{-1}\\sum_{i,t:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)y_{ijt}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing $\\boldsymbol{x}_{t},t\\in\\left\\{1,2,...,T\\right\\}$:\n",
    "\n",
    "### Case #1: $t\\in\\left\\{1,2,...,h_d\\right\\}$\n",
    "\n",
    "**Optimization problem**:\n",
    "$$\\min_{\\boldsymbol{x}_{t}}\\sum_{i,j:(i,j,t)\\in\\Omega}\\left(y_{ijt}-\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)^{\\top}\\boldsymbol{x}_{t}\\right)^{\\top}\\left(y_{ijt}-\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)^{\\top}\\boldsymbol{x}_{t}\\right)+\\lambda_{x}\\boldsymbol{x}_{t}^{\\top}\\boldsymbol{x}_{t}$$\n",
    "\n",
    "**Solution**:\n",
    "$$\\boldsymbol{x}_{t}\\Leftarrow\\left(\\sum_{i,j:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)^{\\top}+\\lambda_{x}I_{R}\\right)^{-1}\\sum_{i,j:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)y_{ijt}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case #2: $t\\in\\left\\{h_d+1,h_d+2,...,T\\right\\}$\n",
    "\n",
    "**Optimization problem**:\n",
    "$$\\min_{\\boldsymbol{x}_{t}}\\sum_{i,j:(i,j,t)\\in\\Omega}\\left(y_{ijt}-\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)^{\\top}\\boldsymbol{x}_{t}\\right)^{\\top}\\left(y_{ijt}-\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)^{\\top}\\boldsymbol{x}_{t}\\right)+\\lambda_{x}\\boldsymbol{x}_{t}^{\\top}\\boldsymbol{x}_{t}\\\\\n",
    "+\\lambda_{ar}\\sum_{k=1,t+h_{k}\\leq T}^{d}\\left(\\boldsymbol{x}_{t+h_k}-\\sum_{l=1}^{d}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t+h_{k}-h_l}\\right)^{\\top}\\left(\\boldsymbol{x}_{t+h_k}-\\sum_{l=1}^{d}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t+h_{k}-h_l}\\right)$$\n",
    "\n",
    "**Solution**:\n",
    "$$\\boldsymbol{x}_{t}\\Leftarrow\\left(\\sum_{i,j:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)^{\\top}+\\lambda_{x}I_{R}+\\lambda_{ar}\\sum_{k=1,t+h_k\\leq T}^{d}\\text{diag}\\left(\\boldsymbol{\\theta}_{k}\\circledast\\boldsymbol{\\theta}_{k}\\right)\\right)^{-1}\\\\\n",
    "\\times\\left(\\sum_{i,j:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)y_{ijt}+\\lambda_{ar}\\sum_{k=1,t+h_k\\leq T}^{d}\\text{diag}\\left(\\boldsymbol{\\theta}_{k}\\right)\\boldsymbol{\\psi}_{t+h_k}\\right)$$\n",
    "where\n",
    "$$\\boldsymbol{\\psi}_{t+h_{k}}=\\boldsymbol{x}_{t+h_k}-\\sum_{l=1,l\\neq k}^{d}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t+h_k-h_l}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Matrix/Tensor Computation Concepts\n",
    "\n",
    "## Khatri-Rao product (`kr_prod`)\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "Given two matrices $A=\\left( \\boldsymbol{a}_1,\\boldsymbol{a}_2,...,\\boldsymbol{a}_r \\right)\\in\\mathbb{R}^{m\\times r}$ and $B=\\left( \\boldsymbol{b}_1,\\boldsymbol{b}_2,...,\\boldsymbol{b}_r \\right)\\in\\mathbb{R}^{n\\times r}$ with same number of columns, then, the **Khatri-Rao product** (or **column-wise Kronecker product**) between $A$ and $B$ is given as follows,\n",
    "\n",
    "$$A\\odot B=\\left( \\boldsymbol{a}_1\\otimes \\boldsymbol{b}_1,\\boldsymbol{a}_2\\otimes \\boldsymbol{b}_2,...,\\boldsymbol{a}_r\\otimes \\boldsymbol{b}_r \\right)\\in\\mathbb{R}^{(mn)\\times r}$$\n",
    "where the symbol $\\odot$ denotes Khatri-Rao product, and $\\otimes$ denotes Kronecker product.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "If $A=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]=\\left( \\boldsymbol{a}_1,\\boldsymbol{a}_2 \\right) $ and $B=\\left[ \\begin{array}{cc} 5 & 6 \\\\ 7 & 8 \\\\ 9 & 10 \\\\ \\end{array} \\right]=\\left( \\boldsymbol{b}_1,\\boldsymbol{b}_2 \\right) $, then, we have\n",
    "\n",
    "$$A\\odot B=\\left( \\boldsymbol{a}_1\\otimes \\boldsymbol{b}_1,\\boldsymbol{a}_2\\otimes \\boldsymbol{b}_2 \\right) $$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cc} \\left[ \\begin{array}{c} 1 \\\\ 3 \\\\ \\end{array} \\right]\\otimes \\left[ \\begin{array}{c} 5 \\\\ 7 \\\\ 9 \\\\ \\end{array} \\right] & \\left[ \\begin{array}{c} 2 \\\\ 4 \\\\ \\end{array} \\right]\\otimes \\left[ \\begin{array}{c} 6 \\\\ 8 \\\\ 10 \\\\ \\end{array} \\right] \\\\ \\end{array} \\right]$$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cc} 5 & 12 \\\\ 7 & 16 \\\\ 9 & 20 \\\\ 15 & 24 \\\\ 21 & 32 \\\\ 27 & 40 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{6\\times 2}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CP combination (`cp_combination`)\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "The CP decomposition factorizes a tensor into a sum of outer products of vectors. For example, for a third-order tensor $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$, the CP decomposition can be written as\n",
    "\n",
    "$$\\hat{\\mathcal{Y}}=\\sum_{s=1}^{r}\\boldsymbol{u}_{s}\\circ\\boldsymbol{v}_{s}\\circ\\boldsymbol{x}_{s},$$\n",
    "or element-wise,\n",
    "\n",
    "$$\\hat{y}_{ijt}=\\sum_{s=1}^{r}u_{is}v_{js}x_{ts},\\forall (i,j,t),$$\n",
    "where vectors $\\boldsymbol{u}_{s}\\in\\mathbb{R}^{m},\\boldsymbol{v}_{s}\\in\\mathbb{R}^{n},\\boldsymbol{x}_{s}\\in\\mathbb{R}^{f}$ are columns of factor matrices $U\\in\\mathbb{R}^{m\\times r},V\\in\\mathbb{R}^{n\\times r},X\\in\\mathbb{R}^{f\\times r}$, respectively. The symbol $\\circ$ denotes vector outer product.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "Given matrices $U=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{2\\times 2}$, $V=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{3\\times 2}$ and $X=\\left[ \\begin{array}{cc} 1 & 5 \\\\ 2 & 6 \\\\ 3 & 7 \\\\ 4 & 8 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{4\\times 2}$, then if $\\hat{\\mathcal{Y}}=\\sum_{s=1}^{r}\\boldsymbol{u}_{s}\\circ\\boldsymbol{v}_{s}\\circ\\boldsymbol{x}_{s}$, then, we have\n",
    "\n",
    "$$\\hat{Y}_1=\\hat{\\mathcal{Y}}(:,:,1)=\\left[ \\begin{array}{ccc} 31 & 42 & 65 \\\\ 63 & 86 & 135 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_2=\\hat{\\mathcal{Y}}(:,:,2)=\\left[ \\begin{array}{ccc} 38 & 52 & 82 \\\\ 78 & 108 & 174 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_3=\\hat{\\mathcal{Y}}(:,:,3)=\\left[ \\begin{array}{ccc} 45 & 62 & 99 \\\\ 93 & 130 & 213 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_4=\\hat{\\mathcal{Y}}(:,:,4)=\\left[ \\begin{array}{ccc} 52 & 72 & 116 \\\\ 108 & 152 & 252 \\\\ \\end{array} \\right].$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor unfolding (`ten2mat`)\n",
    "\n",
    "Using numpy reshape to perform 3rd rank tensor unfold operation. [[**link**](https://stackoverflow.com/questions/49970141/using-numpy-reshape-to-perform-3rd-rank-tensor-unfold-operation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kr_prod(a, b):\n",
    "    return np.einsum('ir, jr -> ijr', a, b).reshape(a.shape[0] * b.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_combination(U, V, X):\n",
    "    return np.einsum('is, js, ts -> ijt', U, V, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRTF(dense_tensor, sparse_tensor, U, V, X, theta, time_lags, \n",
    "         lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter):\n",
    "    dim1, dim2, dim3 = dense_tensor.shape\n",
    "    binary_tensor = np.zeros((dim1, dim2, dim3))\n",
    "    position = np.where(sparse_tensor > 0)\n",
    "    binary_tensor[position] = 1\n",
    "    pos = np.where((dense_tensor > 0) & (sparse_tensor == 0))\n",
    "    d = len(time_lags)\n",
    "    rank = U.shape[1]\n",
    "    \n",
    "    for iters in range(maxiter):\n",
    "        var1 = kr_prod(X, V).T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = np.matmul(var2, ten2mat(binary_tensor, 0).T).reshape([rank, rank, \n",
    "                                                                     dim1]) + np.dstack([lambda_u * np.eye(rank)] * dim1)\n",
    "        var4 = np.matmul(var1, ten2mat(sparse_tensor, 0).T)\n",
    "        for i in range(dim1):\n",
    "            var_Lambda1 = var3[ :, :, i]\n",
    "            inv_var_Lambda1 = np.linalg.inv((var_Lambda1 + var_Lambda1.T)/2)\n",
    "            U[i, :] = np.matmul(inv_var_Lambda1, var4[:, i])\n",
    "\n",
    "        var1 = kr_prod(X, U).T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = np.matmul(var2, ten2mat(binary_tensor, 1).T).reshape([rank, rank, \n",
    "                                                                     dim2]) + np.dstack([lambda_v * np.eye(rank)] * dim2)\n",
    "        var4 = np.matmul(var1, ten2mat(sparse_tensor, 1).T)\n",
    "        for j in range(dim2):\n",
    "            var_Lambda1 = var3[ :, :, j]\n",
    "            inv_var_Lambda1 = np.linalg.inv((var_Lambda1 + var_Lambda1.T)/2)\n",
    "            V[j, :] = np.matmul(inv_var_Lambda1, var4[:, j])\n",
    "\n",
    "        var1 = kr_prod(V, U).T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = np.matmul(var2, ten2mat(binary_tensor, 2).T).reshape([rank, rank, dim3])\n",
    "        var4 = np.matmul(var1, ten2mat(sparse_tensor, 2).T)\n",
    "        for t in range(dim3):\n",
    "            Mt = np.zeros((rank, rank))\n",
    "            Nt = np.zeros(rank)\n",
    "            if t < max(time_lags):\n",
    "                Pt = np.zeros((rank, rank))\n",
    "                Qt = np.zeros(rank)\n",
    "            else:\n",
    "                Pt = np.eye(rank)\n",
    "                Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "            if t < dim3 - np.min(time_lags):\n",
    "                if t >= np.max(time_lags) and t < dim3 - np.max(time_lags):\n",
    "                    index = list(range(0, d))\n",
    "                else:\n",
    "                    index = list(np.where((t + time_lags >= np.max(time_lags)) & (t + time_lags < dim3)))[0]\n",
    "                for k in index:\n",
    "                    theta0 = theta.copy()\n",
    "                    theta0[k, :] = 0\n",
    "                    Mt = Mt + np.diag(theta[k, :] ** 2);\n",
    "                    Nt = Nt + np.multiply(theta[k, :], (X[t + time_lags[k], :] \n",
    "                                                        - np.einsum('ij, ij -> j', theta0,\n",
    "                                                                    X[t + time_lags[k] - time_lags, :])))\n",
    "                X[t, :] = np.matmul(np.linalg.inv(var3[:, :, t]\n",
    "                                                  + lambda_ar * Pt + lambda_ar * Mt + lambda_ar * eta * np.eye(rank)),\n",
    "                                    (var4[:, t] + lambda_ar * Qt + lambda_ar * Nt))\n",
    "            elif t >= dim3 - np.min(time_lags):\n",
    "                X[t, :] = np.matmul(np.linalg.inv(var3[:, :, t]\n",
    "                                                  + lambda_ar * Pt +\n",
    "                                                  lambda_ar * eta * np.eye(rank)), (var4[:, t] + Qt))\n",
    "\n",
    "        for k in range(d):\n",
    "            var1 = X[np.max(time_lags) - time_lags[k] : dim3 - time_lags[k], :]\n",
    "            var2 = np.linalg.inv(np.diag(np.einsum('ij, ij -> j', var1, var1))\n",
    "                                 + (lambda_theta / lambda_ar) * np.eye(rank))\n",
    "            var3 = np.zeros(rank)\n",
    "            for t in range(np.max(time_lags) - time_lags[k], dim3 - time_lags[k]):\n",
    "                var3 += np.multiply(X[t, :], (X[t + time_lags[k], :] \n",
    "                                              - np.einsum('ij, ij -> j', theta, X[t + time_lags[k] - time_lags, :])\n",
    "                                              + np.multiply(theta[k, :], X[t, :])))\n",
    "            theta[k, :] = np.matmul(var2, var3)\n",
    "            \n",
    "        tensor_hat = cp_combination(U, V, X)\n",
    "        mape = np.sum(np.abs(dense_tensor[pos] - \n",
    "                             tensor_hat[pos])/dense_tensor[pos])/dense_tensor[pos].shape[0]\n",
    "        rmse = np.sqrt(np.sum((dense_tensor[pos] -\n",
    "                               tensor_hat[pos])**2)/dense_tensor[pos].shape[0])\n",
    "        \n",
    "        if (iters + 1) % 100 == 0:\n",
    "            print('Iter: {}'.format(iters + 1))\n",
    "            print('MAPE: {:.6}'.format(mape))\n",
    "            print('RMSE: {:.6}'.format(rmse))\n",
    "            print()\n",
    "\n",
    "    return U, V, X, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_prediction(dense_tensor, sparse_tensor, pred_time_steps, back_steps, rank, time_lags, \n",
    "                  lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter):\n",
    "    start_time = dense_tensor.shape[2] - pred_time_steps\n",
    "    dense_tensor0 = dense_tensor[:, :, 0 : start_time]\n",
    "    sparse_tensor0 = sparse_tensor[:, :, 0 : start_time]\n",
    "    dim1, dim2, dim3 = sparse_tensor0.shape\n",
    "    tensor_hat = np.zeros((dim1, dim2, pred_time_steps))\n",
    "    \n",
    "    for t in range(pred_time_steps):\n",
    "        if t == 0:\n",
    "            U0 = 0.1 * np.random.rand(dim1, rank)\n",
    "            V0 = 0.1 * np.random.rand(dim2, rank)\n",
    "            X0 = 0.1 * np.random.rand(dim3, rank)\n",
    "            theta0 = 0.1 * np.random.rand(time_lags.shape[0], rank)\n",
    "            U, V, X, theta = TRTF(dense_tensor0, sparse_tensor0, U0, V0, X0, theta0, time_lags, \n",
    "                                  lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter[0])\n",
    "            U0 = U.copy()\n",
    "            V0 = V.copy()\n",
    "            X0 = np.zeros((dim3 + t + 1, rank))\n",
    "            X0[0 : dim3 + t, :] = X.copy()\n",
    "            X0[dim3 + t, :] = np.einsum('ij, ij -> j', theta, X0[dim3 + t - time_lags, :])\n",
    "            theta0 = theta.copy()\n",
    "        else:\n",
    "            dense_tensor1 = dense_tensor[:, :, start_time - back_steps + t : start_time + t]\n",
    "            sparse_tensor1 = sparse_tensor[:, :, start_time - back_steps + t : start_time + t]\n",
    "            U, V, X, theta = TRTF(dense_tensor1, sparse_tensor1, U0, V0, X0[- back_steps :, :], \n",
    "                                  theta0, time_lags, 0.05 * lambda_u, 0.05 * lambda_v, 0.05 * lambda_ar, \n",
    "                                  0.05 * eta, 0.05 * lambda_theta, maxiter[1])\n",
    "            U0 = U.copy()\n",
    "            V0 = V.copy()\n",
    "            X0 = np.zeros((back_steps + 1, rank))\n",
    "            X0[0 : back_steps, :] = X.copy()\n",
    "            X0[back_steps, :] = np.einsum('ij, ij -> j', theta, X0[back_steps - time_lags, :])\n",
    "            theta0 = theta.copy()\n",
    "        tensor_hat[:, :, t] = np.einsum('ir, jr, r -> ij', U0, V0, X0[-1, :])\n",
    "        if (t + 1) % 40 == 0:\n",
    "            print('Time step: {}'.format(t + 1))\n",
    "            \n",
    "    small_dense_tensor = dense_tensor[:, :, start_time : dense_tensor.shape[2]]\n",
    "    pos = np.where(small_dense_tensor > 0)\n",
    "    final_mape = np.sum(np.abs(small_dense_tensor[pos]\n",
    "                               - tensor_hat[pos])/small_dense_tensor[pos])/small_dense_tensor[pos].shape[0]\n",
    "    final_rmse = np.sqrt(np.sum((small_dense_tensor[pos]\n",
    "                                 - tensor_hat[pos]) ** 2)/small_dense_tensor[pos].shape[0])\n",
    "    print('Final Prediction MAPE: {:.6}'.format(final_mape))\n",
    "    print('Final Prediction RMSE: {:.6}'.format(final_rmse))\n",
    "    print()\n",
    "    return tensor_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../NYC-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "rm_tensor = scipy.io.loadmat('../NYC-data-set/rm_tensor.mat')\n",
    "rm_tensor = rm_tensor['rm_tensor']\n",
    "nm_tensor = scipy.io.loadmat('../NYC-data-set/nm_tensor.mat')\n",
    "nm_tensor = nm_tensor['nm_tensor']\n",
    "\n",
    "missing_rate = 0.1\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(rm_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "# binary_tensor = np.zeros(dense_tensor.shape)\n",
    "# for i1 in range(dense_tensor.shape[0]):\n",
    "#     for i2 in range(dense_tensor.shape[1]):\n",
    "#         for i3 in range(61):\n",
    "#             binary_tensor[i1, i2, i3 * 24 : (i3 + 1) * 24] = np.round(nm_tensor[i1, i2, i3] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "MAPE: 0.532351\n",
      "RMSE: 4.7977\n",
      "\n",
      "Iter: 200\n",
      "MAPE: 0.511658\n",
      "RMSE: 4.76321\n",
      "\n",
      "Time step: 40\n",
      "Time step: 80\n",
      "Time step: 120\n",
      "Time step: 160\n",
      "Final Prediction MAPE: 0.60624\n",
      "Final Prediction RMSE: 6.12827\n",
      "\n",
      "Running time: 281 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 24 * 7\n",
    "back_steps = 24 * 3 * 1\n",
    "rank = 30\n",
    "time_lags = np.array([1, 2, 24])\n",
    "maxiter = np.array([200, 20])\n",
    "theta = 0.1 * np.random.rand(time_lags.shape[0], rank)\n",
    "lambda_u = 500\n",
    "lambda_v = 500\n",
    "lambda_ar = 500\n",
    "eta = 2e-2\n",
    "lambda_theta = 100\n",
    "tensor_hat = st_prediction(dense_tensor, sparse_tensor, pred_time_steps, back_steps, rank, time_lags, \n",
    "                        lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../NYC-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "rm_tensor = scipy.io.loadmat('../NYC-data-set/rm_tensor.mat')\n",
    "rm_tensor = rm_tensor['rm_tensor']\n",
    "nm_tensor = scipy.io.loadmat('../NYC-data-set/nm_tensor.mat')\n",
    "nm_tensor = nm_tensor['nm_tensor']\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(rm_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "# binary_tensor = np.zeros(dense_tensor.shape)\n",
    "# for i1 in range(dense_tensor.shape[0]):\n",
    "#     for i2 in range(dense_tensor.shape[1]):\n",
    "#         for i3 in range(61):\n",
    "#             binary_tensor[i1, i2, i3 * 24 : (i3 + 1) * 24] = np.round(nm_tensor[i1, i2, i3] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "MAPE: 0.516136\n",
      "RMSE: 4.8844\n",
      "\n",
      "Iter: 200\n",
      "MAPE: 0.50344\n",
      "RMSE: 4.87749\n",
      "\n",
      "Time step: 40\n",
      "Time step: 80\n",
      "Time step: 120\n",
      "Time step: 160\n",
      "Final Prediction MAPE: 0.626514\n",
      "Final Prediction RMSE: 6.51707\n",
      "\n",
      "Running time: 307 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 24 * 7\n",
    "back_steps = 24 * 3 * 1\n",
    "rank = 30\n",
    "time_lags = np.array([1, 2, 24])\n",
    "maxiter = np.array([200, 20])\n",
    "theta = 0.1 * np.random.rand(time_lags.shape[0], rank)\n",
    "lambda_u = 500\n",
    "lambda_v = 500\n",
    "lambda_ar = 500\n",
    "eta = 2e-2\n",
    "lambda_theta = 100\n",
    "tensor_hat = st_prediction(dense_tensor, sparse_tensor, pred_time_steps, back_steps, rank, time_lags, \n",
    "                        lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../NYC-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "rm_tensor = scipy.io.loadmat('../NYC-data-set/rm_tensor.mat')\n",
    "rm_tensor = rm_tensor['rm_tensor']\n",
    "nm_tensor = scipy.io.loadmat('../NYC-data-set/nm_tensor.mat')\n",
    "nm_tensor = nm_tensor['nm_tensor']\n",
    "\n",
    "missing_rate = 0.1\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "# binary_tensor = np.round(rm_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        for i3 in range(61):\n",
    "            binary_tensor[i1, i2, i3 * 24 : (i3 + 1) * 24] = np.round(nm_tensor[i1, i2, i3] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "MAPE: 0.529378\n",
      "RMSE: 4.92901\n",
      "\n",
      "Iter: 200\n",
      "MAPE: 0.52452\n",
      "RMSE: 4.9176\n",
      "\n",
      "Time step: 40\n",
      "Time step: 80\n",
      "Time step: 120\n",
      "Time step: 160\n",
      "Final Prediction MAPE: 0.620191\n",
      "Final Prediction RMSE: 6.12192\n",
      "\n",
      "Running time: 320 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 24 * 7\n",
    "back_steps = 24 * 3 * 1\n",
    "rank = 30\n",
    "time_lags = np.array([1, 2, 24])\n",
    "maxiter = np.array([200, 20])\n",
    "theta = 0.1 * np.random.rand(time_lags.shape[0], rank)\n",
    "lambda_u = 500\n",
    "lambda_v = 500\n",
    "lambda_ar = 500\n",
    "eta = 2e-2\n",
    "lambda_theta = 100\n",
    "tensor_hat = st_prediction(dense_tensor, sparse_tensor, pred_time_steps, back_steps, rank, time_lags, \n",
    "                        lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../NYC-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "rm_tensor = scipy.io.loadmat('../NYC-data-set/rm_tensor.mat')\n",
    "rm_tensor = rm_tensor['rm_tensor']\n",
    "nm_tensor = scipy.io.loadmat('../NYC-data-set/nm_tensor.mat')\n",
    "nm_tensor = nm_tensor['nm_tensor']\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "# binary_tensor = np.round(rm_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        for i3 in range(61):\n",
    "            binary_tensor[i1, i2, i3 * 24 : (i3 + 1) * 24] = np.round(nm_tensor[i1, i2, i3] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "MAPE: 0.534226\n",
      "RMSE: 5.15804\n",
      "\n",
      "Iter: 200\n",
      "MAPE: 0.523899\n",
      "RMSE: 5.11326\n",
      "\n",
      "Time step: 40\n",
      "Time step: 80\n",
      "Time step: 120\n",
      "Time step: 160\n",
      "Final Prediction MAPE: 0.693681\n",
      "Final Prediction RMSE: 7.44182\n",
      "\n",
      "Running time: 303 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pred_time_steps = 24 * 7\n",
    "back_steps = 24 * 3 * 1\n",
    "rank = 30\n",
    "time_lags = np.array([1, 2, 24])\n",
    "maxiter = np.array([200, 20])\n",
    "theta = 0.1 * np.random.rand(time_lags.shape[0], rank)\n",
    "lambda_u = 500\n",
    "lambda_v = 500\n",
    "lambda_ar = 500\n",
    "eta = 2e-2\n",
    "lambda_theta = 100\n",
    "tensor_hat = st_prediction(dense_tensor, sparse_tensor, pred_time_steps, back_steps, rank, time_lags, \n",
    "                        lambda_u, lambda_v, lambda_ar, eta, lambda_theta, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of rolling prediction with missing values using TRTF:\n",
    "\n",
    "|  scenario |`lambda_u`|`lambda_v`|`lambda_ar`|`lambda_theta`|`eta`|`rank`|`back_steps`|`time_lags`| `maxiter` | mape | rmse |\n",
    "|:----------|-----:|-----:|-----:|-----:|-----:|-----:|---------:|---------:|---------:|-----------:|----------:|\n",
    "|**Original data**|500|500|500|100|0.02| 30 | $24\\times 3$ | (1,2,24) | (200,20) | **0.6039** | **5.9709**|\n",
    "|**10%, RM**|500|500|500|100|0.02| 30 | $24\\times 3$ | (1,2,24) | (200,20) | **0.6062** | **6.1283**|\n",
    "|**30%, RM**|500|500|500|100|0.02| 30 | $24\\times 3$ | (1,2,24) | (200,20) | **0.6265** | **6.5171**|\n",
    "|**10%, NM**|500|500|500|100|0.02| 30 | $24\\times 3$ | (1,2,24) | (200,20) | **0.6202** | **6.1219**|\n",
    "|**30%, NM**|500|500|500|100|0.02| 30 | $24\\times 3$ | (1,2,24) | (200,20) | **0.6937** | **7.4418**|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
