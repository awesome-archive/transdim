{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Notebook\n",
    "\n",
    "In this notebook, we provide the tensor factorization implementation using an iterative Alternating Least Square (ALS), which is a good starting point for understanding tensor factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Matrix Computation Concepts\n",
    "\n",
    "## 1) Kronecker product\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "Given two matrices $A\\in\\mathbb{R}^{m_1\\times n_1}$ and $B\\in\\mathbb{R}^{m_2\\times n_2}$, then, the **Kronecker product** between these two matrices is defined as\n",
    "\n",
    "$$A\\otimes B=\\left[ \\begin{array}{cccc} a_{11}B & a_{12}B & \\cdots & a_{1m_2}B \\\\ a_{21}B & a_{22}B & \\cdots & a_{2m_2}B \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m_11}B & a_{m_12}B & \\cdots & a_{m_1m_2}B \\\\ \\end{array} \\right]$$\n",
    "where the symbol $\\otimes$ denotes Kronecker product, and the size of resulted $A\\otimes B$ is $(m_1m_2)\\times (n_1n_2)$ (i.e., $m_1\\times m_2$ columns and $n_1\\times n_2$ rows).\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "If $A=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]$ and $B=\\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10 \\\\ \\end{array} \\right]$, then, we have\n",
    "\n",
    "$$A\\otimes B=\\left[ \\begin{array}{cc} 1\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] & 2\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] \\\\ 3\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] & 4\\times \\left[ \\begin{array}{ccc} 5 & 6 & 7\\\\ 8 & 9 & 10\\\\ \\end{array} \\right] \\\\ \\end{array} \\right]$$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cccccc} 5 & 6 & 7 & 10 & 12 & 14 \\\\ 8 & 9 & 10 & 16 & 18 & 20 \\\\ 15 & 18 & 21 & 20 & 24 & 28 \\\\ 24 & 27 & 30 & 32 & 36 & 40 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{4\\times 6}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Khatri-Rao product (`kr_prod`)\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "Given two matrices $A=\\left( \\boldsymbol{a}_1,\\boldsymbol{a}_2,...,\\boldsymbol{a}_r \\right)\\in\\mathbb{R}^{m\\times r}$ and $B=\\left( \\boldsymbol{b}_1,\\boldsymbol{b}_2,...,\\boldsymbol{b}_r \\right)\\in\\mathbb{R}^{n\\times r}$ with same number of columns, then, the **Khatri-Rao product** (or **column-wise Kronecker product**) between $A$ and $B$ is given as follows,\n",
    "\n",
    "$$A\\odot B=\\left( \\boldsymbol{a}_1\\otimes \\boldsymbol{b}_1,\\boldsymbol{a}_2\\otimes \\boldsymbol{b}_2,...,\\boldsymbol{a}_r\\otimes \\boldsymbol{b}_r \\right)\\in\\mathbb{R}^{(mn)\\times r},$$\n",
    "where the symbol $\\odot$ denotes Khatri-Rao product, and $\\otimes$ denotes Kronecker product.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "If $A=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]=\\left( \\boldsymbol{a}_1,\\boldsymbol{a}_2 \\right) $ and $B=\\left[ \\begin{array}{cc} 5 & 6 \\\\ 7 & 8 \\\\ 9 & 10 \\\\ \\end{array} \\right]=\\left( \\boldsymbol{b}_1,\\boldsymbol{b}_2 \\right) $, then, we have\n",
    "\n",
    "$$A\\odot B=\\left( \\boldsymbol{a}_1\\otimes \\boldsymbol{b}_1,\\boldsymbol{a}_2\\otimes \\boldsymbol{b}_2 \\right) $$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cc} \\left[ \\begin{array}{c} 1 \\\\ 3 \\\\ \\end{array} \\right]\\otimes \\left[ \\begin{array}{c} 5 \\\\ 7 \\\\ 9 \\\\ \\end{array} \\right] & \\left[ \\begin{array}{c} 2 \\\\ 4 \\\\ \\end{array} \\right]\\otimes \\left[ \\begin{array}{c} 6 \\\\ 8 \\\\ 10 \\\\ \\end{array} \\right] \\\\ \\end{array} \\right]$$\n",
    "\n",
    "$$=\\left[ \\begin{array}{cc} 5 & 12 \\\\ 7 & 16 \\\\ 9 & 20 \\\\ 15 & 24 \\\\ 21 & 32 \\\\ 27 & 40 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{6\\times 2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kr_prod(a, b):\n",
    "    return np.einsum('ir, jr -> ijr', a, b).reshape(a.shape[0] * b.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 12]\n",
      " [ 7 16]\n",
      " [ 9 20]\n",
      " [15 24]\n",
      " [21 32]\n",
      " [27 40]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8], [9, 10]])\n",
    "print(kr_prod(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) CP decomposition\n",
    "\n",
    "### CP Combination (`cp_combination`)\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "The CP decomposition factorizes a tensor into a sum of outer products of vectors. For example, for a third-order tensor $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$, the CP decomposition can be written as\n",
    "\n",
    "$$\\hat{\\mathcal{Y}}=\\sum_{s=1}^{r}\\boldsymbol{u}_{s}\\circ\\boldsymbol{v}_{s}\\circ\\boldsymbol{x}_{s},$$\n",
    "or element-wise,\n",
    "\n",
    "$$\\hat{y}_{ijt}=\\sum_{s=1}^{r}u_{is}v_{js}x_{ts},\\forall (i,j,t),$$\n",
    "where vectors $\\boldsymbol{u}_{s}\\in\\mathbb{R}^{m},\\boldsymbol{v}_{s}\\in\\mathbb{R}^{n},\\boldsymbol{x}_{s}\\in\\mathbb{R}^{f}$ are columns of factor matrices $U\\in\\mathbb{R}^{m\\times r},V\\in\\mathbb{R}^{n\\times r},X\\in\\mathbb{R}^{f\\times r}$, respectively. The symbol $\\circ$ denotes vector outer product.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "Given matrices $U=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{2\\times 2}$, $V=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{3\\times 2}$ and $X=\\left[ \\begin{array}{cc} 1 & 5 \\\\ 2 & 6 \\\\ 3 & 7 \\\\ 4 & 8 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{4\\times 2}$, then if $\\hat{\\mathcal{Y}}=\\sum_{s=1}^{r}\\boldsymbol{u}_{s}\\circ\\boldsymbol{v}_{s}\\circ\\boldsymbol{x}_{s}$, then, we have\n",
    "\n",
    "$$\\hat{Y}_1=\\hat{\\mathcal{Y}}(:,:,1)=\\left[ \\begin{array}{ccc} 31 & 42 & 65 \\\\ 63 & 86 & 135 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_2=\\hat{\\mathcal{Y}}(:,:,2)=\\left[ \\begin{array}{ccc} 38 & 52 & 82 \\\\ 78 & 108 & 174 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_3=\\hat{\\mathcal{Y}}(:,:,3)=\\left[ \\begin{array}{ccc} 45 & 62 & 99 \\\\ 93 & 130 & 213 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_4=\\hat{\\mathcal{Y}}(:,:,4)=\\left[ \\begin{array}{ccc} 52 & 72 & 116 \\\\ 108 & 152 & 252 \\\\ \\end{array} \\right].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_combine(U, V, X):\n",
    "    return np.einsum('is, js, ts -> ijt', U, V, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 31  38  45  52]\n",
      "  [ 42  52  62  72]\n",
      "  [ 65  82  99 116]]\n",
      "\n",
      " [[ 63  78  93 108]\n",
      "  [ 86 108 130 152]\n",
      "  [135 174 213 252]]]\n",
      "\n",
      "tensor size:\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "U = np.array([[1, 2], [3, 4]])\n",
    "V = np.array([[1, 3], [2, 4], [5, 6]])\n",
    "X = np.array([[1, 5], [2, 6], [3, 7], [4, 8]])\n",
    "print(cp_combine(U, V, X))\n",
    "print()\n",
    "print('tensor size:')\n",
    "print(cp_combine(U, V, X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Tensor Unfolding (`ten2mat`)\n",
    "\n",
    "Using numpy reshape to perform 3rd rank tensor unfold operation. [[**link**](https://stackoverflow.com/questions/49970141/using-numpy-reshape-to-perform-3rd-rank-tensor-unfold-operation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size:\n",
      "(3, 2, 4)\n",
      "original tensor:\n",
      "[[[ 1  2  3  4]\n",
      "  [ 3  4  5  6]]\n",
      "\n",
      " [[ 5  6  7  8]\n",
      "  [ 7  8  9 10]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [11 12 13 14]]]\n",
      "\n",
      "(1) mode-1 tensor unfolding:\n",
      "[[ 1  3  2  4  3  5  4  6]\n",
      " [ 5  7  6  8  7  9  8 10]\n",
      " [ 9 11 10 12 11 13 12 14]]\n",
      "\n",
      "(2) mode-2 tensor unfolding:\n",
      "[[ 1  5  9  2  6 10  3  7 11  4  8 12]\n",
      " [ 3  7 11  4  8 12  5  9 13  6 10 14]]\n",
      "\n",
      "(3) mode-3 tensor unfolding:\n",
      "[[ 1  5  9  3  7 11]\n",
      " [ 2  6 10  4  8 12]\n",
      " [ 3  7 11  5  9 13]\n",
      " [ 4  8 12  6 10 14]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[[1, 2, 3, 4], [3, 4, 5, 6]], \n",
    "              [[5, 6, 7, 8], [7, 8, 9, 10]], \n",
    "              [[9, 10, 11, 12], [11, 12, 13, 14]]])\n",
    "print('tensor size:')\n",
    "print(X.shape)\n",
    "print('original tensor:')\n",
    "print(X)\n",
    "print()\n",
    "print('(1) mode-1 tensor unfolding:')\n",
    "print(ten2mat(X, 0))\n",
    "print()\n",
    "print('(2) mode-2 tensor unfolding:')\n",
    "print(ten2mat(X, 1))\n",
    "print()\n",
    "print('(3) mode-3 tensor unfolding:')\n",
    "print(ten2mat(X, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Tensor CP Factorization using ALS (TF-ALS)\n",
    "\n",
    "Regarding CP factorization as a machine learning problem, we could perform a learning task by minimizing the loss function over factor matrices, that is,\n",
    "\n",
    "$$\\min _{U, V, X} \\sum_{(i, j, t) \\in \\Omega}\\left(y_{i j t}-\\sum_{r=1}^{R}u_{ir}v_{jr}x_{tr}\\right)^{2}.$$\n",
    "\n",
    "Within this optimization problem, multiplication among three factor matrices (acted as parameters) makes this problem difficult. Alternatively, we apply the ALS algorithm for CP factorization.\n",
    "\n",
    "In particular, the optimization problem for each row $\\boldsymbol{u}_{i}\\in\\mathbb{R}^{R},\\forall i\\in\\left\\{1,2,...,M\\right\\}$ of factor matrix $U\\in\\mathbb{R}^{M\\times R}$ is given by\n",
    "\n",
    "$$\\min _{\\boldsymbol{u}_{i}} \\sum_{j,t:(i, j, t) \\in \\Omega}\\left[y_{i j t}-\\boldsymbol{u}_{i}^\\top\\left(\\boldsymbol{x}_{t}\\odot\\boldsymbol{v}_{j}\\right)\\right]\\left[y_{i j t}-\\boldsymbol{u}_{i}^\\top\\left(\\boldsymbol{x}_{t}\\odot\\boldsymbol{v}_{j}\\right)\\right]^\\top.$$\n",
    "\n",
    "The least square for this optimization is\n",
    "\n",
    "$$u_{i} \\Leftarrow\\left(\\sum_{j, t, i, j, t ) \\in \\Omega} \\left(x_{t} \\odot v_{j}\\right)\\left(x_{t} \\odot v_{j}\\right)^{\\top}\\right)^{-1}\\left(\\sum_{j, t :(i, j, t) \\in \\Omega} y_{i j t} \\left(x_{t} \\odot v_{j}\\right)\\right), \\forall i \\in\\{1,2, \\ldots, M\\}.$$\n",
    "\n",
    "The alternating least squares for $V\\in\\mathbb{R}^{N\\times R}$ and $X\\in\\mathbb{R}^{T\\times R}$ are\n",
    "\n",
    "$$\\boldsymbol{v}_{j}\\Leftarrow\\left(\\sum_{i,t:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{x}_{t}\\odot\\boldsymbol{u}_{i}\\right)\\left(\\boldsymbol{x}_{t}\\odot\\boldsymbol{u}_{i}\\right)^\\top\\right)^{-1}\\left(\\sum_{i,t:(i,j,t)\\in\\Omega}y_{ijt}\\left(\\boldsymbol{x}_{t}\\odot\\boldsymbol{u}_{i}\\right)\\right),\\forall j\\in\\left\\{1,2,...,N\\right\\},$$\n",
    "\n",
    "$$\\boldsymbol{x}_{t}\\Leftarrow\\left(\\sum_{i,j:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{v}_{j}\\odot\\boldsymbol{u}_{i}\\right)\\left(\\boldsymbol{v}_{j}\\odot\\boldsymbol{u}_{i}\\right)^\\top\\right)^{-1}\\left(\\sum_{i,j:(i,j,t)\\in\\Omega}y_{ijt}\\left(\\boldsymbol{v}_{j}\\odot\\boldsymbol{u}_{i}\\right)\\right),\\forall t\\in\\left\\{1,2,...,T\\right\\}.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_ALS(sparse_tensor, rank, maxiter):\n",
    "    dim1, dim2, dim3 = sparse_tensor.shape\n",
    "    dim = np.array([dim1, dim2, dim3])\n",
    "    \n",
    "    U = 0.1 * np.random.rand(dim1, rank)\n",
    "    V = 0.1 * np.random.rand(dim2, rank)\n",
    "    X = 0.1 * np.random.rand(dim3, rank)\n",
    "    \n",
    "    pos = np.where(sparse_tensor != 0)\n",
    "    binary_tensor = np.zeros((dim1, dim2, dim3))\n",
    "    binary_tensor[pos] = 1\n",
    "    tensor_hat = np.zeros((dim1, dim2, dim3))\n",
    "    \n",
    "    for iters in range(maxiter):\n",
    "        for order in range(dim.shape[0]):\n",
    "            if order == 0:\n",
    "                var1 = kr_prod(X, V).T\n",
    "            elif order == 1:\n",
    "                var1 = kr_prod(X, U).T\n",
    "            else:\n",
    "                var1 = kr_prod(V, U).T\n",
    "            var2 = kr_prod(var1, var1)\n",
    "            var3 = np.matmul(var2, ten2mat(binary_tensor, order).T).reshape([rank, rank, dim[order]])\n",
    "            var4 = np.matmul(var1, ten2mat(sparse_tensor, order).T)\n",
    "            for i in range(dim[order]):\n",
    "                var_Lambda = var3[ :, :, i]\n",
    "                inv_var_Lambda = inv((var_Lambda + var_Lambda.T)/2 + 10e-12 * np.eye(rank))\n",
    "                vec = np.matmul(inv_var_Lambda, var4[:, i])\n",
    "                if order == 0:\n",
    "                    U[i, :] = vec.copy()\n",
    "                elif order == 1:\n",
    "                    V[i, :] = vec.copy()\n",
    "                else:\n",
    "                    X[i, :] = vec.copy()\n",
    "\n",
    "        tensor_hat = cp_combine(U, V, X)\n",
    "        mape = np.sum(np.abs(sparse_tensor[pos] - tensor_hat[pos])/sparse_tensor[pos])/sparse_tensor[pos].shape[0]\n",
    "        rmse = np.sqrt(np.sum((sparse_tensor[pos] - tensor_hat[pos]) ** 2)/sparse_tensor[pos].shape[0])\n",
    "        \n",
    "        if (iters + 1) % 100 == 0:\n",
    "            print('Iter: {}'.format(iters + 1))\n",
    "            print('Training MAPE: {:.6}'.format(mape))\n",
    "            print('Training RMSE: {:.6}'.format(rmse))\n",
    "            print()\n",
    "    \n",
    "    return tensor_hat, U, V, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Data Organization\n",
    "\n",
    "## 1) Matrix Structure\n",
    "\n",
    "We consider a dataset of $m$ discrete time series $\\boldsymbol{y}_{i}\\in\\mathbb{R}^{f},i\\in\\left\\{1,2,...,m\\right\\}$. The time series may have missing elements. We express spatio-temporal dataset as a matrix $Y\\in\\mathbb{R}^{m\\times f}$ with $m$ rows (e.g., locations) and $f$ columns (e.g., discrete time intervals),\n",
    "\n",
    "$$Y=\\left[ \\begin{array}{cccc} y_{11} & y_{12} & \\cdots & y_{1f} \\\\ y_{21} & y_{22} & \\cdots & y_{2f} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_{m1} & y_{m2} & \\cdots & y_{mf} \\\\ \\end{array} \\right]\\in\\mathbb{R}^{m\\times f}.$$\n",
    "\n",
    "## 2) Tensor Structure\n",
    "\n",
    "We consider a dataset of $m$ discrete time series $\\boldsymbol{y}_{i}\\in\\mathbb{R}^{nf},i\\in\\left\\{1,2,...,m\\right\\}$. The time series may have missing elements. We partition each time series into intervals of predifined length $f$. We express each partitioned time series as a matrix $Y_{i}$ with $n$ rows (e.g., days) and $f$ columns (e.g., discrete time intervals per day),\n",
    "\n",
    "$$Y_{i}=\\left[ \\begin{array}{cccc} y_{11} & y_{12} & \\cdots & y_{1f} \\\\ y_{21} & y_{22} & \\cdots & y_{2f} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_{n1} & y_{n2} & \\cdots & y_{nf} \\\\ \\end{array} \\right]\\in\\mathbb{R}^{n\\times f},i=1,2,...,m,$$\n",
    "\n",
    "therefore, the resulting structure is a tensor $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to transform a data set into something we can use for time series imputation?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Experiments on Guangzhou Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario:\n",
    "# binary_tensor = np.zeros(dense_tensor.shape)\n",
    "# for i1 in range(dense_tensor.shape[0]):\n",
    "#     for i2 in range(dense_tensor.shape[1]):\n",
    "#         binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Given only the partially observed data $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$, how can we impute the unknown missing values?\n",
    "\n",
    "The main influential factors for such imputation model are:\n",
    "\n",
    "- `rank`.\n",
    "\n",
    "- `maxiter`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Training MAPE: 0.0809251\n",
      "Training RMSE: 3.47736\n",
      "\n",
      "Iter: 200\n",
      "Training MAPE: 0.0805399\n",
      "Training RMSE: 3.46261\n",
      "\n",
      "Iter: 300\n",
      "Training MAPE: 0.0803688\n",
      "Training RMSE: 3.45631\n",
      "\n",
      "Iter: 400\n",
      "Training MAPE: 0.0802661\n",
      "Training RMSE: 3.45266\n",
      "\n",
      "Iter: 500\n",
      "Training MAPE: 0.0801768\n",
      "Training RMSE: 3.44986\n",
      "\n",
      "Iter: 600\n",
      "Training MAPE: 0.0800948\n",
      "Training RMSE: 3.44755\n",
      "\n",
      "Iter: 700\n",
      "Training MAPE: 0.0800266\n",
      "Training RMSE: 3.4456\n",
      "\n",
      "Iter: 800\n",
      "Training MAPE: 0.0799675\n",
      "Training RMSE: 3.44365\n",
      "\n",
      "Iter: 900\n",
      "Training MAPE: 0.07992\n",
      "Training RMSE: 3.4419\n",
      "\n",
      "Iter: 1000\n",
      "Training MAPE: 0.079885\n",
      "Training RMSE: 3.44058\n",
      "\n",
      "Final Imputation MAPE: 0.0833307\n",
      "Final Imputation RMSE: 3.59283\n",
      "\n",
      "Running time: 2908 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 80\n",
    "maxiter = 1000\n",
    "tensor_hat, U, V, X = CP_ALS(sparse_tensor, rank, maxiter)\n",
    "pos = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "final_mape = np.sum(np.abs(dense_tensor[pos] - tensor_hat[pos])/dense_tensor[pos])/dense_tensor[pos].shape[0]\n",
    "final_rmse = np.sqrt(np.sum((dense_tensor[pos] - tensor_hat[pos]) ** 2)/dense_tensor[pos].shape[0])\n",
    "print('Final Imputation MAPE: {:.6}'.format(final_mape))\n",
    "print('Final Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "print()\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of missing data imputation using TF-ALS:\n",
    "\n",
    "|  scenario |`rank`| `maxiter`|       mape |      rmse |\n",
    "|:----------|-----:|---------:|-----------:|----------:|\n",
    "|**20%, RM**|   80 |     1000 | **0.0833** | **3.5928**|\n",
    "|**40%, RM**|   80 |     1000 | **0.0837** | **3.6190**|\n",
    "|**20%, NM**|   10 |     1000 | **0.1027** | **4.2960**|\n",
    "|**40%, NM**|   10 |     1000 | **0.1028** | **4.3274**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Experiments on Birmingham Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Birmingham-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Birmingham-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario:\n",
    "# binary_tensor = np.zeros(dense_tensor.shape)\n",
    "# for i1 in range(dense_tensor.shape[0]):\n",
    "#     for i2 in range(dense_tensor.shape[1]):\n",
    "#         binary_tensor[i1, i2, :] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Training MAPE: 0.0509401\n",
      "Training RMSE: 15.3163\n",
      "\n",
      "Iter: 200\n",
      "Training MAPE: 0.0498774\n",
      "Training RMSE: 14.9599\n",
      "\n",
      "Iter: 300\n",
      "Training MAPE: 0.0490062\n",
      "Training RMSE: 14.768\n",
      "\n",
      "Iter: 400\n",
      "Training MAPE: 0.0481006\n",
      "Training RMSE: 14.6343\n",
      "\n",
      "Iter: 500\n",
      "Training MAPE: 0.0474233\n",
      "Training RMSE: 14.5365\n",
      "\n",
      "Iter: 600\n",
      "Training MAPE: 0.0470442\n",
      "Training RMSE: 14.4642\n",
      "\n",
      "Iter: 700\n",
      "Training MAPE: 0.0469617\n",
      "Training RMSE: 14.4082\n",
      "\n",
      "Iter: 800\n",
      "Training MAPE: 0.0470459\n",
      "Training RMSE: 14.3623\n",
      "\n",
      "Iter: 900\n",
      "Training MAPE: 0.0472333\n",
      "Training RMSE: 14.3235\n",
      "\n",
      "Iter: 1000\n",
      "Training MAPE: 0.047408\n",
      "Training RMSE: 14.2898\n",
      "\n",
      "Final Imputation MAPE: 0.0583358\n",
      "Final Imputation RMSE: 18.9148\n",
      "\n",
      "Running time: 38 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 30\n",
    "maxiter = 1000\n",
    "tensor_hat, U, V, X = CP_ALS(sparse_tensor, rank, maxiter)\n",
    "pos = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "final_mape = np.sum(np.abs(dense_tensor[pos] - tensor_hat[pos])/dense_tensor[pos])/dense_tensor[pos].shape[0]\n",
    "final_rmse = np.sqrt(np.sum((dense_tensor[pos] - tensor_hat[pos]) ** 2)/dense_tensor[pos].shape[0])\n",
    "print('Final Imputation MAPE: {:.6}'.format(final_mape))\n",
    "print('Final Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "print()\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of missing data imputation using TF-ALS:\n",
    "\n",
    "|  scenario |`rank`| `maxiter`|       mape |       rmse |\n",
    "|:----------|-----:|---------:|-----------:|-----------:|\n",
    "|**10%, RM**|   30 |     1000 | **0.0615** | **18.5005**|\n",
    "|**30%, RM**|   30 |     1000 | **0.0583** | **18.9148**|\n",
    "|**10%, NM**|   10 |     1000 | **0.1447** | **41.6710**|\n",
    "|**30%, NM**|   10 |     1000 | **0.1765** | **63.8465**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Experiments on Hangzhou Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario:\n",
    "# binary_tensor = np.zeros(dense_tensor.shape)\n",
    "# for i1 in range(dense_tensor.shape[0]):\n",
    "#     for i2 in range(dense_tensor.shape[1]):\n",
    "#         binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Training MAPE: 0.176548\n",
      "Training RMSE: 17.0263\n",
      "\n",
      "Iter: 200\n",
      "Training MAPE: 0.174888\n",
      "Training RMSE: 16.8609\n",
      "\n",
      "Iter: 300\n",
      "Training MAPE: 0.175056\n",
      "Training RMSE: 16.7835\n",
      "\n",
      "Iter: 400\n",
      "Training MAPE: 0.174988\n",
      "Training RMSE: 16.7323\n",
      "\n",
      "Iter: 500\n",
      "Training MAPE: 0.175013\n",
      "Training RMSE: 16.6942\n",
      "\n",
      "Iter: 600\n",
      "Training MAPE: 0.174928\n",
      "Training RMSE: 16.6654\n",
      "\n",
      "Iter: 700\n",
      "Training MAPE: 0.174722\n",
      "Training RMSE: 16.6441\n",
      "\n",
      "Iter: 800\n",
      "Training MAPE: 0.174565\n",
      "Training RMSE: 16.6284\n",
      "\n",
      "Iter: 900\n",
      "Training MAPE: 0.174454\n",
      "Training RMSE: 16.6159\n",
      "\n",
      "Iter: 1000\n",
      "Training MAPE: 0.174409\n",
      "Training RMSE: 16.6054\n",
      "\n",
      "Final Imputation MAPE: 0.209776\n",
      "Final Imputation RMSE: 100.315\n",
      "\n",
      "Running time: 279 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 50\n",
    "maxiter = 1000\n",
    "tensor_hat, U, V, X = CP_ALS(sparse_tensor, rank, maxiter)\n",
    "pos = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "final_mape = np.sum(np.abs(dense_tensor[pos] - tensor_hat[pos])/dense_tensor[pos])/dense_tensor[pos].shape[0]\n",
    "final_rmse = np.sqrt(np.sum((dense_tensor[pos] - tensor_hat[pos]) ** 2)/dense_tensor[pos].shape[0])\n",
    "print('Final Imputation MAPE: {:.6}'.format(final_mape))\n",
    "print('Final Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "print()\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of missing data imputation using TF-ALS:\n",
    "\n",
    "|  scenario |`rank`| `maxiter`|       mape |      rmse |\n",
    "|:----------|-----:|---------:|-----------:|----------:|\n",
    "|**20%, RM**|   50 |     1000 | **0.1991** |**111.303**|\n",
    "|**40%, RM**|   50 |     1000 | **0.2098** |**100.315**|\n",
    "|**20%, NM**|    5 |     1000 | **0.2837** |**42.6136**|\n",
    "|**40%, NM**|    5 |     1000 | **0.2811** |**38.4201**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Experiments on New York Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/NYC-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "rm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/rm_tensor.mat')\n",
    "rm_tensor = rm_tensor['rm_tensor']\n",
    "nm_tensor = scipy.io.loadmat('../datasets/NYC-data-set/nm_tensor.mat')\n",
    "nm_tensor = nm_tensor['nm_tensor']\n",
    "\n",
    "missing_rate = 0.1\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "# binary_tensor = np.round(rm_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        for i3 in range(61):\n",
    "            binary_tensor[i1, i2, i3 * 24 : (i3 + 1) * 24] = np.round(nm_tensor[i1, i2, i3] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Training MAPE: 0.511739\n",
      "Training RMSE: 4.07981\n",
      "\n",
      "Iter: 200\n",
      "Training MAPE: 0.501094\n",
      "Training RMSE: 4.0612\n",
      "\n",
      "Iter: 300\n",
      "Training MAPE: 0.504264\n",
      "Training RMSE: 4.05578\n",
      "\n",
      "Iter: 400\n",
      "Training MAPE: 0.507211\n",
      "Training RMSE: 4.05119\n",
      "\n",
      "Iter: 500\n",
      "Training MAPE: 0.509956\n",
      "Training RMSE: 4.04623\n",
      "\n",
      "Iter: 600\n",
      "Training MAPE: 0.51046\n",
      "Training RMSE: 4.04129\n",
      "\n",
      "Iter: 700\n",
      "Training MAPE: 0.509797\n",
      "Training RMSE: 4.03294\n",
      "\n",
      "Iter: 800\n",
      "Training MAPE: 0.509531\n",
      "Training RMSE: 4.02976\n",
      "\n",
      "Iter: 900\n",
      "Training MAPE: 0.509265\n",
      "Training RMSE: 4.02861\n",
      "\n",
      "Iter: 1000\n",
      "Training MAPE: 0.508873\n",
      "Training RMSE: 4.02796\n",
      "\n",
      "Final Imputation MAPE: 0.540363\n",
      "Final Imputation RMSE: 5.66633\n",
      "\n",
      "Running time: 742 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 30\n",
    "maxiter = 1000\n",
    "tensor_hat, U, V, X = CP_ALS(sparse_tensor, rank, maxiter)\n",
    "pos = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "final_mape = np.sum(np.abs(dense_tensor[pos] - tensor_hat[pos])/dense_tensor[pos])/dense_tensor[pos].shape[0]\n",
    "final_rmse = np.sqrt(np.sum((dense_tensor[pos] - tensor_hat[pos]) ** 2)/dense_tensor[pos].shape[0])\n",
    "print('Final Imputation MAPE: {:.6}'.format(final_mape))\n",
    "print('Final Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "print()\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of missing data imputation using TF-ALS:\n",
    "\n",
    "|  scenario |`rank`| `maxiter`|       mape |      rmse |\n",
    "|:----------|-----:|---------:|-----------:|----------:|\n",
    "|**10%, RM**|   30 |     1000 | **0.5262** | **6.2444**|\n",
    "|**30%, RM**|   30 |     1000 | **0.5488** | **6.8968**|\n",
    "|**10%, NM**|   30 |     1000 | **0.5170** | **5.9863**|\n",
    "|**30%, NM**|   30 |     100 | **-** | **-**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8: Experiments on Seattle Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "RM_tensor = RM_mat.reshape([RM_mat.shape[0], 28, 288])\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(RM_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Training MAPE: 0.0749497\n",
      "Training RMSE: 4.47036\n",
      "\n",
      "Iter: 200\n",
      "Training MAPE: 0.0745197\n",
      "Training RMSE: 4.44713\n",
      "\n",
      "Iter: 300\n",
      "Training MAPE: 0.0741685\n",
      "Training RMSE: 4.43496\n",
      "\n",
      "Iter: 400\n",
      "Training MAPE: 0.0739049\n",
      "Training RMSE: 4.42523\n",
      "\n",
      "Iter: 500\n",
      "Training MAPE: 0.0737243\n",
      "Training RMSE: 4.41692\n",
      "\n",
      "Iter: 600\n",
      "Training MAPE: 0.0735726\n",
      "Training RMSE: 4.40994\n",
      "\n",
      "Iter: 700\n",
      "Training MAPE: 0.073415\n",
      "Training RMSE: 4.4034\n",
      "\n",
      "Iter: 800\n",
      "Training MAPE: 0.0732484\n",
      "Training RMSE: 4.3976\n",
      "\n",
      "Iter: 900\n",
      "Training MAPE: 0.0731012\n",
      "Training RMSE: 4.393\n",
      "\n",
      "Iter: 1000\n",
      "Training MAPE: 0.0729675\n",
      "Training RMSE: 4.38843\n",
      "\n",
      "Final Imputation MAPE: 0.0741996\n",
      "Final Imputation RMSE: 4.49292\n",
      "\n",
      "Running time: 2594 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 50\n",
    "maxiter = 1000\n",
    "tensor_hat, U, V, X = CP_ALS(sparse_tensor, rank, maxiter)\n",
    "pos = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "final_mape = np.sum(np.abs(dense_tensor[pos] - tensor_hat[pos])/dense_tensor[pos])/dense_tensor[pos].shape[0]\n",
    "final_rmse = np.sqrt(np.sum((dense_tensor[pos] - tensor_hat[pos]) ** 2)/dense_tensor[pos].shape[0])\n",
    "print('Final Imputation MAPE: {:.6}'.format(final_mape))\n",
    "print('Final Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "print()\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "RM_tensor = RM_mat.reshape([RM_mat.shape[0], 28, 288])\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_tensor = np.round(RM_tensor + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Training MAPE: 0.0747491\n",
      "Training RMSE: 4.4544\n",
      "\n",
      "Iter: 200\n",
      "Training MAPE: 0.074195\n",
      "Training RMSE: 4.42842\n",
      "\n",
      "Iter: 300\n",
      "Training MAPE: 0.0738864\n",
      "Training RMSE: 4.4162\n",
      "\n",
      "Iter: 400\n",
      "Training MAPE: 0.0735955\n",
      "Training RMSE: 4.40699\n",
      "\n",
      "Iter: 500\n",
      "Training MAPE: 0.0733999\n",
      "Training RMSE: 4.40083\n",
      "\n",
      "Iter: 600\n",
      "Training MAPE: 0.0732636\n",
      "Training RMSE: 4.3959\n",
      "\n",
      "Iter: 700\n",
      "Training MAPE: 0.0731835\n",
      "Training RMSE: 4.39241\n",
      "\n",
      "Iter: 800\n",
      "Training MAPE: 0.0731367\n",
      "Training RMSE: 4.3899\n",
      "\n",
      "Iter: 900\n",
      "Training MAPE: 0.0730982\n",
      "Training RMSE: 4.38779\n",
      "\n",
      "Iter: 1000\n",
      "Training MAPE: 0.0730573\n",
      "Training RMSE: 4.38571\n",
      "\n",
      "Final Imputation MAPE: 0.0757934\n",
      "Final Imputation RMSE: 4.5574\n",
      "\n",
      "Running time: 2706 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 50\n",
    "maxiter = 1000\n",
    "tensor_hat, U, V, X = CP_ALS(sparse_tensor, rank, maxiter)\n",
    "pos = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "final_mape = np.sum(np.abs(dense_tensor[pos] - tensor_hat[pos])/dense_tensor[pos])/dense_tensor[pos].shape[0]\n",
    "final_rmse = np.sqrt(np.sum((dense_tensor[pos] - tensor_hat[pos]) ** 2)/dense_tensor[pos].shape[0])\n",
    "print('Final Imputation MAPE: {:.6}'.format(final_mape))\n",
    "print('Final Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "print()\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "NM_mat = pd.read_csv('../datasets/Seattle-data-set/NM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "NM_mat = NM_mat.values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 28, 288))\n",
    "for i1 in range(binary_tensor.shape[0]):\n",
    "    for i2 in range(binary_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(NM_mat[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Training MAPE: 0.100191\n",
      "Training RMSE: 5.60051\n",
      "\n",
      "Iter: 200\n",
      "Training MAPE: 0.0981896\n",
      "Training RMSE: 5.51405\n",
      "\n",
      "Iter: 300\n",
      "Training MAPE: 0.0969386\n",
      "Training RMSE: 5.46377\n",
      "\n",
      "Iter: 400\n",
      "Training MAPE: 0.0967974\n",
      "Training RMSE: 5.45581\n",
      "\n",
      "Iter: 500\n",
      "Training MAPE: 0.0966243\n",
      "Training RMSE: 5.44397\n",
      "\n",
      "Iter: 600\n",
      "Training MAPE: 0.0960368\n",
      "Training RMSE: 5.42168\n",
      "\n",
      "Iter: 700\n",
      "Training MAPE: 0.0958292\n",
      "Training RMSE: 5.41295\n",
      "\n",
      "Iter: 800\n",
      "Training MAPE: 0.0957371\n",
      "Training RMSE: 5.40865\n",
      "\n",
      "Iter: 900\n",
      "Training MAPE: 0.0956582\n",
      "Training RMSE: 5.40568\n",
      "\n",
      "Iter: 1000\n",
      "Training MAPE: 0.095595\n",
      "Training RMSE: 5.40339\n",
      "\n",
      "Final Imputation MAPE: 0.0994999\n",
      "Final Imputation RMSE: 5.63311\n",
      "\n",
      "Running time: 351 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "maxiter = 1000\n",
    "tensor_hat, U, V, X = CP_ALS(sparse_tensor, rank, maxiter)\n",
    "pos = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "final_mape = np.sum(np.abs(dense_tensor[pos] - tensor_hat[pos])/dense_tensor[pos])/dense_tensor[pos].shape[0]\n",
    "final_rmse = np.sqrt(np.sum((dense_tensor[pos] - tensor_hat[pos]) ** 2)/dense_tensor[pos].shape[0])\n",
    "print('Final Imputation MAPE: {:.6}'.format(final_mape))\n",
    "print('Final Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "print()\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "NM_mat = pd.read_csv('../datasets/Seattle-data-set/NM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "NM_mat = NM_mat.values\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 28, 288])\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario\n",
    "### Set the NM scenario by:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 28, 288))\n",
    "for i1 in range(binary_tensor.shape[0]):\n",
    "    for i2 in range(binary_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(NM_mat[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Training MAPE: 0.0996282\n",
      "Training RMSE: 5.55963\n",
      "\n",
      "Iter: 200\n",
      "Training MAPE: 0.0992568\n",
      "Training RMSE: 5.53825\n",
      "\n",
      "Iter: 300\n",
      "Training MAPE: 0.0986723\n",
      "Training RMSE: 5.51806\n",
      "\n",
      "Iter: 400\n",
      "Training MAPE: 0.0967838\n",
      "Training RMSE: 5.46447\n",
      "\n",
      "Iter: 500\n",
      "Training MAPE: 0.0962312\n",
      "Training RMSE: 5.44762\n",
      "\n",
      "Iter: 600\n",
      "Training MAPE: 0.0961017\n",
      "Training RMSE: 5.44322\n",
      "\n",
      "Iter: 700\n",
      "Training MAPE: 0.0959531\n",
      "Training RMSE: 5.43927\n",
      "\n",
      "Iter: 800\n",
      "Training MAPE: 0.0958815\n",
      "Training RMSE: 5.43619\n",
      "\n",
      "Iter: 900\n",
      "Training MAPE: 0.0958781\n",
      "Training RMSE: 5.4344\n",
      "\n",
      "Iter: 1000\n",
      "Training MAPE: 0.0958921\n",
      "Training RMSE: 5.43266\n",
      "\n",
      "Final Imputation MAPE: 0.10038\n",
      "Final Imputation RMSE: 5.7034\n",
      "\n",
      "Running time: 304 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "maxiter = 1000\n",
    "tensor_hat, U, V, X = CP_ALS(sparse_tensor, rank, maxiter)\n",
    "pos = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "final_mape = np.sum(np.abs(dense_tensor[pos] - tensor_hat[pos])/dense_tensor[pos])/dense_tensor[pos].shape[0]\n",
    "final_rmse = np.sqrt(np.sum((dense_tensor[pos] - tensor_hat[pos]) ** 2)/dense_tensor[pos].shape[0])\n",
    "print('Final Imputation MAPE: {:.6}'.format(final_mape))\n",
    "print('Final Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "print()\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment results** of missing data imputation using TF-ALS:\n",
    "\n",
    "|  scenario |`rank`| `maxiter`|       mape |      rmse |\n",
    "|:----------|-----:|---------:|-----------:|----------:|\n",
    "|**20%, RM**|   50 |     1000 | **0.0742** |**4.4929**|\n",
    "|**40%, RM**|   50 |     1000 | **0.0758** |**4.5574**|\n",
    "|**20%, NM**|   10 |     1000 | **0.0995** |**5.6331**|\n",
    "|**40%, NM**|   10 |     1000 | **0.1004** |**5.7034**|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
